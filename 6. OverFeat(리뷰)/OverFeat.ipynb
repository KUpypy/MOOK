{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense evaluation은 Yann LeCun의 지도하에 Pierre Sermanet이 발표한 논문 <br /> \n",
    "“OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks”에 처음 소개되었다. <br />\n",
    "CNN의 classifier로 흔히 사용되는 FC 레이어를 1x1 convolution 개념으로 사용하게 되면, 고정된 이미지뿐만 아니라 다양한 크기의 이미지를 sliding window 방식으로 <br /> \n",
    "처리할 수 있으며, feature extraction 블럭의 맨 마지막 단에 오는 max pooling 레이어의 전 후 처리 방식을 조금만 바꾸면, 기존 CNN 방식보다 조밀하게<br />\n",
    "(dense) feature extraction, localization 및 detection을 수행할 수 있게 된다. 물론 multi-crop 방식보다 연산량 관점에서도 매우 효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverFeat과 다른 알고리즘 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeat은 classification, localization 및 detection에 대한 통합 프레임워크를 제공하는 것을 목표로 개발이 되었으며, 2013년 ILSVRC 대회의 localization 부문에서 <br /> \n",
    "1위를 차지하였고, classification과 detection 분야에서도 우수한 성적(각각 4위와 3위)을 보였다. <br /> \n",
    "2012년 ILSVRC에서 우승을 차지한 AlexNet은 classification 분야에 대해서는 상세한 설명을 하고 있지만, localization에 대한 설명은 거의 없으며, <br />\n",
    "2013년부터 새롭게 대회에 추가된 detection 분야는 고려하고 있지 않다. <br />\n",
    "OverFeat 설계팀은 classification, localization  및 detection 각 분야에 ConvNet을 효과적으로 사용할 수 있음을 보여주는 것을 논문의 목표로 삼았다. <br /> \n",
    "실제로 2013년에 ILSVRC에서 3분야에 모두 출전한 팀은 OverFeat 팀이 유일하다. <br /> \n",
    "그런데 Classification 분야에서는 뒤에 GoogLeNet, VGGNet 및 ResNet과 같은 구조가 속속 발표되면서 역시 관심에서 멀어지게 된다. <br /> \n",
    "또한 시기적으로는 OverFeat보다 늦은 2013년에 발표된 R-CNN이 selective search 방법을 적용하여 OverFeat보다 큰 성능차를 보이면서, OverFeat의 가치는 빛을 잃게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeat는 1-pass로 연산이 가능한 구조를 취하고 있기 때문에, 약 2000여개의 후보 영역에 ConvNet 연산을 해야 하는 R-CNN 보다 연산량 관점에서 효과적이었으며, <br /> \n",
    "뒤에 R-CNN의 문제점을 해결한 SPPNet 설계자들에게 힌트가 되었다. <br /> \n",
    "SPPNet 역시 1-pass 구조를 취하고 있는데, 이들은 OverFeat이 사용한 dense evaluation방법보다 더 진보된 Spatial Pyramid Pooling(SPP) 방식을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification, Localization & Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification은 특정 대상이 이미지 내에 존재하는지 여부를 판단하는 것을 말하며, 보통은 5개의 후보를 추정하고 그것을 ground-truth와 비교하여 판단한다. <br />\n",
    "5개의 후보 중 하나가 ground-truth와 맞는 것이 있으면 맞는 것으로 보며, 이것을 top-5 에러율로 표현하여 classification의 성능을 비교하는 지표로 삼는다. <br /> \n",
    "아래 그림은 leopard 를 제대로 인식할 수 있는지 확인하는 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/1.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "localization은 bounding box를 통해 물체의 존재하는 영역까지 파악하는 것을 말하며, classification과 같은 학습 데이터를 사용하고 최대 5개까지 bounding box를 <br /> \n",
    "통해 후보를 내고 ground-truth와 비교하여 50% 이상 영역이 일치하면 맞는 것으로 본다. 성능 지표는 에러율(error rate)이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection은 classification/localization과 달리 200 class 학습 데이터를 사용하며, 이미지 내에 존재하는 object를 가능한 많이 추정을 하며, <br /> 경우에 따라서 없는 경우는 0이 되어야 하고, 추정이 틀린 false positive에 대해서는 감점을 준다. <br /> \n",
    "R-CNN 에서 보았던 것처럼 보통은 mAP(mean Average Precision)으로 결과를 나타낸다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/3.png\" width=550 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverFeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeat은 fast와 accurate 2개의 모델이 있으며, fast 모델은 AlexNet과 마찬가지로 5 layer의 ConV 레이어 / pooling 레이어 및 3개의 FC 레이어로 구성이 된다. <br /> \n",
    "Accurate model은 연산 시간은 좀 더 걸리더라도 정확도 향상을 위해 Conv 레이어 / pooling 레이어가 1개 더 추가되었다. <br /> \n",
    "아래 표는 fast model 구조에 대한 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 표에서 볼 수 있는 것처럼, CNN의 전형적인 구조를 취하고 있으며, VGGNet에서처럼, LRN(Local Response Normalization)은 별 효과가 없다고 하여 사용하지 않고 있으며, <br /> \n",
    "AlexNet에서 사용된 overlapped pooling 대신에 non-overlapped pooling 방식을 사용하고 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습(Training) 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification의 학습에는 모든 학습 이미지를 256 크기로 scaling 하고 221x221 크기로 multi-crop을 한다. <br /> \n",
    "AlexNet과 마찬가지로 코너에서 4개 중앙에서 1개, 총 5개의 영상을 무작위로 고르고, 이것들과 좌우반전 영상 총 10개의 이미지를 학습 이미지로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing 방법 - Multi scale dense evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeat은 muti crop voting 방식 대신에 dense evaluation 방식을 사용하였다. <br /> \n",
    "Multi-corp voting을 사용하는 경우는 서로 겹치는 부분이 있더라도 ConvNet 연산을 전부 새롭게 해야 되지만, dense evaluation 방식을 사용하여 이 문제를 해결하였다. <br />\n",
    "Dense evaluation 방식의 개념은 다음 그림과 같다. 이 그림은 이해를 돕기 위해 1차원으로 표시한 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약에 최종 max pooling 레이어에 총 20개의 데이터가 있고, 이것에 대해 3x1 non-overlapped pooling을 한다고 해보자. <br /> \n",
    "Pooling을 거치고 나면 데이터의 양이 1/3로 줄어드는 것뿐만 아니라, 해상도(resolution) 역시 1/3 로 줄어들기 때문에 위치의 정확도도 그만큼 떨어지게 된다. <br />\n",
    "그런데 위 그림처럼, offset Δ를 1 데이터 단위로 하게 되면, 1 데이터 간격으로 각각 pooling을 진행하고, 그 결과를 Classifier에 적용을 하게 되면, <br />\n",
    "pooling 이전의 해상도를 유지할 수 있어, pooling 이후 1번만 classifier 연산을 하는 것에 비해 훨씬 조밀한 검사(dense evaluation)을 할 수 있게 되는 것이다. <br />\n",
    "아래는 accurate model의 구성을 보여주는 그림이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/6.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accurate model에서 stride 부분을 주목해서 살펴보면, Layer 1에서 convolution와 pooling을 거치면 영상의 크기가 1/6로 줄어든다. <br /> Layer2를 거치면 다시 1/2로 줄어들고, Layer6의 pooling을 거치면, 다시 1/3이 줄어들어 전체적으로 Layer6를 거치고 나면, <br /> \n",
    "Layer7의 classifier로 입력의 1 픽셀은 실제 입력 영상의 36픽셀에 해당하게 된다. <br />\n",
    "OverFeat의 입력 영상의 크기가 221x221인 것을 감안하면, Layer7의 1 픽셀의 해상도가 36픽셀에 해당하기 때문에 너무 간격이 듬성 듬성하게 된다. <br />\n",
    "그래서 OverFeat 설계자가 고려한 부분은 classifier에 연결되는 Layer6의 pooling 부분에 주목을 하였다. <br /> \n",
    "Pooling의 stride가 3x3이기 때문에 pooling 레이어 앞 단의 해상도는 36픽셀이 아니라 12 픽셀 수준이 되며, pooling 이전 단 기준으로 1픽셀씩 offset을 갖고 <br /> \n",
    "pooling을 수행하면 classifier로 들어가는 데이터의 양은 결과적으로 3x3, 즉 9배만큼 많아지지만, 해상도는 그만큼 좋아지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverFeat에서 설계팀은 FC 레이어에 대한 해석을 다르게 하였다. LeCun이 FC 레이어에 대해 언급한 유명한 말은 다음과 같다. <br />\n",
    "'In Convolutional Nets, there is no such thing as \"fully-connected layers\". <br /> \n",
    "There are only convolution layers with 1x1 convolution kernels and a full connection table.' LeCun은 FC 레이어를 1x1 convolution으로 이해를 하고 있다. <br /> \n",
    "LeCun의 말처럼, FC-layer를 1x1 convolution으로 본다면, Conv / pooling 레이어를 처리할 때와 마찬가지로 sliding window 개념을 적용할 수 있다. <br />\n",
    "그간 ConvNet 설계자들이 어려워했던 부분은 convolution 부분은 이미지의 크기에 상관없이 적용이 가능하지만, FC 레이어 부분은 고정된 size를 갖고 있기 때문에 <br /> \n",
    "sliding window 개념이 아니라, ConvNet 앞 단에서 고정된 size를 고려한 crop을 수행하고 항상 FC layer 앞단에는 동일한 크기의 feature map이 확보되도록 하였다. <br />\n",
    "그렇지만, FC 레이어가 개념적으로 보면 1x1 convolution으로 볼 수 있기 때문에 이제는 FC 레이어 앞 단의 feature map 크기에 연연해 할 이유가 없어지는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 개념을 2차원 구조를 갖는 이미지에 적용하게 되면, 간단하게 예시는 아래 그림과 같다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/7.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상단은 학습 과정을 보여준다. 입력 이미지의 크기가 14x14인 경우에 Conv / pooling을 거처 최종적으로 5x5 크기를 얻은 후 classifier를 거쳐 학습을 한다. <br /> \n",
    "하단은 입력 이미지보다 크기가 큰 16x16 영상을 test 입력으로 사용하게 된다면, FC 레이어 앞 단에서는 6x6 크기의 feature map이 얻어지고, <br /> \n",
    "이것은 sliding window 개념으로 해석하면, 5x5 window 4개가 있는 것으로 볼 수 있고, 최종적으로 2x2 차원의 최종 출력을 얻게 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 개념이 확보되었으므로 이제는 큰 이미지의 특정 위치를 무작위로 선택하는 것이 아니라 일정한 resolution 단위로 선택을 할 수 있게 된다. <br /> \n",
    "또한 이미지의 scale이 바뀌더라도, 바뀐 scale에 맞춰 sliding window를 움직이면서 결과를 얻으면 된다. <br />\n",
    "아래 그림은 4개의 scale에 대해 dense evaluation을 보여주는 그림이다. <br /> \n",
    "Scale에 따라 특정 대상이 나타났다가 사라질 수 있으며, voting 개념을 활용하여 대상을 classification 및 localization 시킬 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/8.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Localization은 대상의 위치나 형태에 맞춰 bounding box까지 학습을 해줘야 한다. <br /> \n",
    "Classification과 동일한 학습 이미지에 대해 bounding box까지 있는 ground-truth 데이터를 이용해 localization을 학습시킨다. <br />\n",
    "Classification과 많은 부분을 공유하며, 최종단에 있는 classifier 부분을 bounding box regression network로 치환해주고, <br /> \n",
    "bounding box를 각각의 위치 및 scale에 맞게 학습을 시킨다. <br />\n",
    "아래 그림은 동일 이미지에 대하여 voting에 의해 특정 대상이 검출되고 대상에 맞춰 bounding box를 찾아주는 것을 보여주는 그림이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/9.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop의 경우처럼 원본 학습 이미지로부터 이미지를 잘라낸 후 그것들을 각각 ConvNet에 적용시키는 방식이 아니라, 큰 이미지에 대해 곧바로 ConvNet을 적용하고 <br /> \n",
    "일정한 픽셀 간격(grid)으로 마치 sliding window를 적용하듯이 결과를 끌어낼 수 있어, 연산량 관점에서는 매우 효율적이다. <br />\n",
    "하지만 grid 크기 문제로 인해서 학습 결과가 약간 떨어질 수 있다. 그러므로 crop과 dense evaluation을 상보적으로(complementary) 섞어 사용하면 더 성능이 좋아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OverFeat 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 OverFeat의 실험 결과이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/10.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과를 보면, model voting과 4 scale, dense evaluation을 사용한 경우 top-5 에러율이 13.24%로 상당히 좋은 결과를 낸다는 것을 알 수 있다. <br /> \n",
    "Dense evaluation을 사용하면, 겹치는 부분에 대한 연산을 공유할 수 있어 전반적으로 연산량이 크게 줄어든다. <br /> \n",
    "Grid 크기에 대한 우려가 있을 수 있지만, grid 크기를 연산량과 고려하여 적절한 수준으로 유지하면 결과가 좋다. <br />\n",
    "___\n",
    "Localization 결과는 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/11.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "앞서 살펴본 것처럼, OverFeat는 ConvNet의 FC 레이어를 1x1 convolution 개념으로 볼 수 있다는 점을 이용하여 연산량 절감 차원에서는 효과적이었다. <br /> \n",
    "하지만 근본적으로는 deeper network 이상의 성능을 얻을 수는 없었다. <br />\n",
    "그래도 ConvNet을 이용하여 localization / detection까지 통합 시도를 했다는 점에서 의미가 있고, 1년 뒤에 마이크로소프트 팀에서 발표할 SPPNet에 <br />\n",
    "맥이 닿아 있다는 점에서 의미가 있다. SPPNet은 dense evaluation 대신에 spatial pyramid pooling을 적용하여 detection 의 성능과 속도를 모두 개선시킬 수 있었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
