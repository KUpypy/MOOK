{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014년 ILSRC에서 옥스포드 대학교의 VGGNet은 GoogLeNet에 근소한 차이로 2위를 차지한다. <br />\n",
    "하지만 구조적 측면에서 보면 GoogLeNet보다 훨씬 간단한 구조로 되어 있어 이해가 쉽고 변형을 시켜가면서 테스트 하기 용이하기 때문에 오히려 GoogLeNet보다 더 많이 사용한다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크의 깊이(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet 이전의 CNN들은 기껏해야 깊이가 8 레이어 수준이었다. 하지만 2014년 GoogLeNet과 VGGNet 모두 이전 구조에 비해 깊이가 훨씬 deep해 진다. <br />\n",
    "이후 2015년에 발표된 마이크로소프트의 ResNet은 무려 152 레이어로 깊어진다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 네트워크를 깊게 설계하는 이유는 훨씬 더 복잡한 문제를 풀게하기 위해서이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 그림은 VGGNet과 AlexNet의 구조를 비교하는 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "깊이에서 차이가 나지만, 전반적으로 그 구조는 LeNet-5 및 AlexNet과 크게 다르지 않음을 확인할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet의 원래 개발 목적은 네트워크의 깊이(depth)가 성능에 어떤 영향을 주는지 연구하기 위함이었다. <br />\n",
    "오직 깊이가 어떤 영향을 주는지 밝히기 위해, receptive field의 크기를 가장 간단한 3x3으로 고정하고 깊이를 다르게 한 6개의 구조에 대하여 실험을 한다. <br />\n",
    "여기서 주목해야 할 점은, 3x3 kernel을 여러 번 사용하는 것이 5x5, 7x7 혹은 그 이상의 크기를 같은 kernel로 한 번 convolution을 하는 것 보다 파라미터의 수를 줄일 수 있다. <br />\n",
    "아래 표는 실험에 사용한 6개의 구조를 보여준다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet은 AlexNet이나 ZFNet처럼 224x224 크기의 color 이미지를 입력으로 사용하며 1개 혹은 그 이상의 Conv 레이어에 뒤이어 max pooling 레이어가 오는 <br /> \n",
    "단순한 구조로 되어 있다. 또한 기존의 CNN 구조처럼 맨 마지막 단에 FC 레이어가 온다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet의 단점은 파라미터의 갯수가 너무 많다는 것이다. <br />\n",
    "아래의 표를 보면 알 수 있는 것처럼\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet의 파라미터 갯수가 5 millions 수준이었던것에 비해 VGGNet은 가장 단순한 A 구조에서도 파라미터의 갯수가 133 millions 로 엄청나게 많다. <br />\n",
    "그 이유는 VGGNet의 경우 AlexNet과 마찬가지로 맨 마지막 단에 FC 레이어가 3개가 오는데, 이 부분에서만 파라미터의 갯수가 약 122 millions로 엄청나게 많다. <br />\n",
    "하지만 GoogLeNet의 경우는 FC 레이어가 없다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 표는 16 레이어 VGGNet(구조 D)에서 필요한 파라미터의 메모리 소요량을 정리한 것이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/6.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet의 특이한 점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGGNet에서 A-LRN은 Local Response Normalization이 적용된 구조인데, 예상과는 달리 VGGNet의 구조에서는 LRN이 별 효과가 없어 이후 구조에서는 사용하지 않는다. <br />\n",
    "- 1x1이 적용되기는 하지만, 적용하는 목적이 GoogLeNet의 경우처럼 차원을 줄이기 위한 목적이라기 보다는 차원은 그대로 유지하면서 ReLU를 이용하여 추가적인 비선형성을 확보하기 위함이다.\n",
    "- Deep한 네트워크는 학습할 때 vanishing/exploding 그라디언트 문제로 학습이 어려워질 수 있다. <br />\n",
    "이를 해결하기 위해 11 레이어의 비교적 간단한 구조 A를 먼저 학습시킨 후 더 깊은 나머지 구조를 학습할 때는 처음 4 레이어와 마지막 FC 레이어는 구조 A의 <br /> \n",
    "학습 결과로 파라미터를 초기화 한 후 학습을 진행하여 이 문제를 해결하였다. <br />\n",
    "(GoogLeNet의 경우 auxiliary classifier를 사용하여 이 문제를 해결하였다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크를 깊게 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GooLeNet은 네트워크를 깊게 만들면서 파라미터의 수를 줄이기 위해 Inception이라는 독특한 구조를 만들었고, 학습을 돕기 위해 axiliary classifier라는 개념을 고안했다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet 연구팀은 깊은 네트워크의 독특한 구조를 설계하는 것이 목적이 아니라, 네트워크의 깊이가 어떤 영향을 끼치는지 확인하기 위해 가장 단순한 구조인 3x3 filter를 겹처서 <br /> \n",
    "사용하는 방법을 선택하였으며 여러 개의 구조 실험을 통해, 깊이가 어느정도 이상이 되면 성능 개선의 효과가 미미해지는 저점이 있음을 확인하였다. <br />\n",
    "ILSVR-2012 데이터의 경우, 16 레이어를 넘어서면 별다른 이득이 없는 것으로 확인되었다. 몇 개의 레이어가 최적인지는 학습 데이터의 갯수나 해결하고자 하는 <br /> \n",
    "문제의 성격에 따라 달라질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet의 기본 개념은 다음 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/7.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN의 기본 구조는 Conv 레이어 다음에 해상도를 줄이기 위한 pooling 레이어가 오는 구조인데, 여기서 주황색 부분에 receptive field의 크기가 3x3인 filter를 여러 개 쌓는 구조를 택하였다. 이렇게 3x3 filter의 Conv 레이어를 2개 쌓으면 5x5 filter의 Conv 레이어가 되고, 3개를 쌓으면 7x7 filter의 Conv 레이어가 된다. <br />\n",
    "이렇게 함으로서 파라미터의 수를 줄일 수 있고, 그로 인해 학습 속도가 빨라진다. 또한 레이어의 갯수가 많아질수록 비선형성이 더 증가하기 때문에 보다 더 유용하고 <br /> \n",
    "다양한 feature를 추출하기 좋다. 실제로도 5x5 filter의 Conv 레이어 하나보다는 3x3 filter의 Conv 레이어 2개로 구현하는 것이 결과가 더 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11-레이어의 구조에서 중간에, 아래의 그림처럼 화살표의 위치에 Conv 레이어를 추가하여 13-레이어 구조로 만들고, 13-레이어의 구조에 다시 Conv 레이어를 추가하여 <br />\n",
    "16-레이어의 구조로 발전시켰다. 구조의 발전 방향은 아래의 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크가 깊어지면 vanishing/exploding 그라디언트의 문제로 인하여 학습에 어려움이 생기는데, 이를 해결하기 위해 VGGNet은 11-레이어 구조의 학습 결과를 <br /> \n",
    "더 깊은 layer를 가지는 네트워크의 파라미터를 초기화하는데 사용함으로써 학습 시간을 줄이고, vanishing 그라디언트 문제도 해결하였다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet에서 성능을 끌어올리기 위해 적용한 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2012에는 1000개의 클래스가 있으며, 각각의 클래스에는 약 1000장 정도의 학습 이미지가 있다. <br />\n",
    "클래스당 1000장의 학습 데이터는 절대 많다고 볼 수 없으며, 과적합에 빠지지 않도록 학습 방법을 잘 설정해주어야 한다. <br />\n",
    "이 때 사용한 기법이 학습 데이터의 양을 늘리기 위한 data augmentation 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet은 모든 학습 이미지들을 256x256의 크기로 만든 후, 해당 이미지에서 무작위로 224x224 크기의 이미지를 취하는 방식으로 학습 데이터의 크리를 2048배로 증가시켰으며, <br />\n",
    "주성분 분석(PCA)를 사용하여 RGB 채널의 값을 조작하는 방식도 사용하였다. 하지만 AlexNet에서는 모든 이미지를 256x256 크기의 single scale 만을 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 GooLeNet에서는 영상의 가로/세로 비율을 [3/4, 4/3]의 범위를 유지하면서 원래 이미지의 8%부터 100%까지 포함하는 다양한 크기의 patch를 학습에 사용하였다. <br />\n",
    "또한 photometric distortion을 통해 학습 데이터의 양을 늘렸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet에서는 training scale을 'S'로 표시하며, single scale training과 multi scaling training을 모두 지원한다. <br />\n",
    "Single scale에서는 S=256(AlexNet과 같음)과 S=384 두 개의 scale을 지원한다. <br />\n",
    "Mulit scale에서는 S를 Smin과 Smax 범위에서 무작위로 선택할 수 있게 하였으며, Smin=256 Smax=512이다. <br />\n",
    "즉, 256과 512 범위에서 무작위로 scale을 정할 수 있기 때문에 다양한 크기에 대한 대응이 가능하여 정확도가 올라간다. <br />\n",
    "Multi scale 학습은 S=384로 미리 학습을 시킨 후 S를 무작위로 선택해가며 fine tuning을 한다. <br />\n",
    "S를 무작위로 바꿔 가면서 학습을 시킨다고 하여, 이것을 scale jittering이라고 한다. <br />\n",
    "이렇게 크기 조정을 통해 얻은 학습 이미지들로부터 AlexNet과 마찬가지 방식으로 무작위로 224x224 크기를 선택하며, RGB 채널의 성분에 대한 변경 역시 <br />\n",
    "AlexNet과 비슷한 방법으로 수행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Testing 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Test는 학습된 뉴럴 네트워크에서 최적의 결과를 도출해내는 것이 목적이며, 대부분 학습 이미지로부터 여러 개의 patch 혹은 crop을 이용하여, 가능한 많은 <br />\n",
    "test 이미지를 만들어 낸 후 여러 이미지들로부터의 결과를 투표(voting)을 통해 가장 기대되는 것을 최종 test 결과로 정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "AlexNet의 경우 Test 이미지를 256x256의 크기로 scaling하고, 그 이미지를 4 개의 코너와 중앙에서 224x224의 크기로 잘라(CNN에서는 crop이라고 함)서 <br />\n",
    "5개의 이미지를 만들고, 이것을 좌우 반전시켜 총 10장의 test 이미지를 만들어 냈다. 10장의 테스트 이미지를 네트워크에 집어넣고 10개의 결과를 평균하는 <br />\n",
    "방식으로 최종 출력을 결정하였다. Softmax의 결과가 숫자로 나오기 때문에 출력된 결과들의 평균을 가지고 클래스를 결정하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet의 경우는 테스트 이미지를 256x256 1개의 scale만 사용하는 것이 아니라, 256, 288, 320, 352 총 4개의 scale로 만들고 각각의 scale로 부터 <br />\n",
    "3장의 정사각형 이미지를 선택하고, 다시 선택된 이미지로부터 4개의 코너 및 센터 2개를 취해 총 6장의 224x224 크기의 영상을 취하고, 각각을 좌우반전시켜 <br />\n",
    "4x3x6x2, 총 144개의 테스트 이미지를 만들어 낸다. 결과에 대해서는 voting을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "VGGNet은 'Q'라고 부르는 test scale을 사용하며, 테스트 이미지를 미리 정한 Q로 크기를 조정한다. Q는 training scale S와 같을 필요가 없으며, <br />\n",
    "각각의 S에 대해 여러 개의 Q를 사용하게 되면 학습의 결과는 좋아진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "VGGNet의 경우는 GoogLeNet과 같은 multi-crop(GoogLeNet은 144장, VGGNet은 150장)방식의 테스트 이미지 augmentation 기법을 적용하였지만, <br />\n",
    "연산량을 줄이기 위해 OverFeat 구조에서 사용한 dense evaluation 기법을 적용하였다. 최종적으로는 multi crop과 dense evaluation 기법을 혼합하여 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dense evaluation의 장점은 crop의 경우처럼 원본 학습 이미지로부터 이미지를 잘라낸 후 그것들을 각각 ConvNet에 적용시키는 방식이 아니라, <br />\n",
    "큰 이미지에 대하여 곧바로 ConvNet을 적용하고 일정한 픽셀 간격(grid)으로 마치 sliding window를 적용하듯이 결과를 이끌어 낼수 있어, <br />\n",
    "연산량 관점에서는 매우 효율적이지만, grid의 크기 문제로 인하여 학습 결과가 약간 떨어질 수 있다. 그러므로 crop과 dense evaluation을 상호보완적으로 <br />\n",
    "혼합하여 사용하면 더 좋은 성능을 낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## VGGNet의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "VGGNet에 single scale test 이미지를 적용하였을 때의 결과는 아래의 표와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./Images/9.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "네트워크가 깊어질수록 결과가 좋아지고, 학습에 scale jittering을 사용한 경우에 결과가 더 좋다는 것을 확인할 수 있다. <br />\n",
    "B 구조에서 3x3 Conv 레이어를 2개 겹처서 사용하는 경우와 5x5 Conv 레이어 1개를 사용하는 모델을 각각 만들어서 실험을 했는데, 결과는 3x3 2개를 사용하는 것이 <br />\n",
    "5x5 1개보다 top-1 error rates에서 7%정도 결과가 좋았다고 한다. <br />\n",
    "큰 크기의 filter를 적게 사용하는 것보다, 작은 크기의 filter를 여러 개 사용하는 것은 단순히 네트워크를 깊게 만들고 파라미터의 수를 줄여줄 수 있을 뿐 아니라 <br />\n",
    "네트워크의 비선형성이 강화됨으로서 feature를 추출하는 능력이 더 좋아지게 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi scale test 결과는 아래 표와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/10.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi scale test는 S가 고정된 경우는 {S-32, S, S+32}로 Q 값을 변화시키면서 테스트를 하였다. <br /> \n",
    "여기서 학습의 scale과 테스트의 scale이 차 많이 차이가 나게되면 오히려 결과가 더 좋지 못하므로 32만큼 차이가 나게 하여 테스트를 하였다. <br />\n",
    "학습에 scale jittering을 적용한 경우는 출력의 크기는 [256, 384, 512]로 테스트 이미지의 크기를 정하였으며, 예상대로 scale jittering을 적용하지 않은 것 보다 훨씬 결과가 좋았다. <br />\n",
    "single scale 보다는 multi scale이 결과가 더 좋다는 것을 확인 할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/11.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi crop은 grid 크기의 문제로 인해 multi crop 하나만 적용하였을 경우는 성능 향상의 효과가 미비하였지만, 상호보완적인 특성을 가지고 있는 dense evalutaion를 함께 적용하였을 때는 <br /\n",
    "성능이 꽤 향상되는 것을 아래의 표를 통해 확인 할 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로 VGGNet은 그 구조가 간단하여 이해나 변형이 쉬운 장점을 가지고 있지만, 파라미터의 수가 지나치게 많기 때문에 학습에 시간이 오래 걸린다는 약점을 가지고 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
