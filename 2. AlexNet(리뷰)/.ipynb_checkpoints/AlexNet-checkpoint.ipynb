{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "캐나다의 토론토 대학에서 ImageNet 이미지 데이터 베이스를 기반으로 한 ILSVRC(ImageNet Large Scale Recognition Challenge)-2012 의 우승을 차지한다. <br />\n",
    "당시 논문의 1저자가 바로 Alex Khrizevsky 였으며, 이 사람의 이름을 따서 이들이 개발한 CNN 아키텍처를 AlexNet이라고 부른다. <br />\n",
    "아래의 그림의 SuperVision은 AlexNet을 의미한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과에서 알 수 있듯이, 당시 AlexNet은 압도적인 성능으로 1위를 차지하였다. <br />\n",
    "AlexNet은 구조적 관점에서 보았을 때, Yann LeCun의 LeNet5와 크게 다르지 않지만, 성능을 높이기 위한 여러 기법들과 특히 GPU를 사용하여 의미있는 결과를 얻어내었다. <br />\n",
    "이후 CNN 아키텍처를 설계할 때 GPU를 사용하는 것이 대세가 되었다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet의 기본구조\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet의 기본 구조는 위의 그림과 같으며, 전체적으로 보았을 때 2개의 GPU를 기반으로 한 병렬 구조인 점을 제외하면, LeNet-5와 대부분 유사하다. <br />\n",
    "AlexNet은 총 5개의 Conv 레이어와 3개의 fully-connected 레이어로 구성되어 있으며, 맨 마지막 FC 레이어는 1000개의 카테고리로 분류를 위해 <br />\n",
    "활성화 함수로 softmax 함수를 사용한다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet은 약 0.65 millions 개의 뉴런, 60 millions 개의 파라미터 및 630 millions 개의 connection으로 구성된 매우 큰 CNN 아키텍처를 가지고 있다. <br />\n",
    "이를 학습하기위해 2개의 GPU를 사용하였다. 당시에 사용한 GPU는 엔디비아 GTX580을 사용하였다. <br /> \n",
    "이는 3GB의 메모리를 가지고 있기 때문에, 네트워크의 구조를 결정하는데에도 3GB의 메모리 한계에 맞추어 CNN 아키텍처를 설계하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet-세부 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet의 블록 구조를 이해하려면 CNN은 아래의 그림과 같이 3차원 구조를 갖는다는 것을 이해하여야 한다. <br />\n",
    "이미지의 크기는 Width와 Height 그리고 Depth를 갖는다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 Color 이미지의 경우 R/G/B 3개의 값을 가진다. <br />\n",
    "처음 Depth의 크기는 3이지만 convolution을 거치면서 feature map이 만들어지고 kernel(filter)의 갯수에 따라 중간 feature map의 depth가 달라진다. <br />\n",
    "(Depth는 채널이라고도 함)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet의 경우 입력 이미지의 크기가 32x32로 작았기 때문에 모든 Conv 레이어는 동일하게 5x5의 크기를 갖는 kernel을 사용했다. <br />\n",
    "입력 이미지의 크기도 흑백 이미지이기 때문에 Depth는 1이다. 이때도 마찬가지로 Convolution을 거치면서 Depth가 증가하게 되었다. <br />\n",
    "하지만 AlexNet의 경우는 입력 이미지의 크기가 227x227x3으로 매우 증가하였기 때문에 첫 번째 Conv 레이어의 kernel의 크기를 11x11x3으로 비교적 큰 receptive field를 사용하였다. <br />\n",
    "첫 번째 Conv 레이어에서 stride의 크기는 4를 적용하였고, 96개의 서로 다른 kernel들을 사용하여 결과로 55x55x96의 feature map을 얻는다. <br />\n",
    "이때 AlexNet의 첫 번째 Conv 레이어는 55x55x96=290,400 개의 뉴런들로 구성되어 있고, 각 kernel은 11x11x3=363개의 가중치 및 1개의 bias를 <br />\n",
    "파라미터로 가지기 때문에 따라서 kernel당 364개의 파라미터를 가진다. <br />\n",
    "이때 kernel은 총 96개 이므로 364x96=34,944개의 파라미터, 290,400x364=105,750,600개의 connection이 만들어진다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림을 보면, 첫 번째 Conv 레이어를 거치고나면 96개의 feature map을 얻을 수 있으며 GPU1에서는 주로 컬러와 상관없는 정보를 추출하기 위한 kernel이 학습되고, <br />\n",
    "GPU-2에서는 주로 color에 관련된 정보를 추출하기 위한 kernel이 학습된다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/6.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 Conv 레이어 뒤에 바로 두 번째 Conv 레이어가 뒤이어 나온다. 두 번째 Conv 레이어는 5x5x48의 크기를 갖는 256개의 kernel을 사용하고 있다. <br />\n",
    "첫 번째 Conv 레이어에서는 연산의 수를 줄이기 위해 stride를 4로 설정하여 자연스럽게 pooling을 한 것 처럼 출력되는 feature map의 크기가 줄어들게 하였다. <br />\n",
    "세 번째 Conv 레이어에서 연산을 하기 전에 response normalization과 max pooling을 적용하여, 출력되는 feature map의 크기는 27x27x256으로 줄어들게 된다. <br />\n",
    "세 번째 Conv 레이어의 연산에서 3x3x256의 크기를 갖는 384개의 kernel을 사용하여 convolution 연산을 수행하고 13x13x384 크기의 feature map을 얻는다. <br />\n",
    "이 때 GPU-1과 GPU-2의 결과를 합쳐서 사용한다. <br />\n",
    "그 결과에 대하여 다시 response normalization과 pooling을 거쳐 13x13x384 크기의 feature map을 얻는다. <br />\n",
    "그 결과에 대하여 네 번째 Conv 레이어, 다섯 번째 Conv 레이어를 거치게 되고 최종 Convolution을 거친 feature map은 pooling 과정을 거쳐 총 4,096개의 뉴런을 <br /> \n",
    "가진 FC 레이어에 연결된다. <br />\n",
    "최종 레이어에서는 1,000개의 카테고리에 대하여 결과를 낼 수 있도록 softmax 함수가 적용된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet-성능 개선을 위한 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet이 성능 향상을 위해 사용한 기법들은 ReLU, Overlapping pooling, Response Normalization, Dropout, 2개의 GPU 사용 등이 있다. <br />\n",
    "먼저 ReLU에 대해서 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 뉴럴 네트워크의 활성화 함수로는 sigmoid와 tanh를 사용하였는데 이 두 함수는 학습 속도가 느리다는 단점이 있다. <br />\n",
    "네트워크의 크기가 작을 때는 그 차이가 심각하지 않지만, AlexNet과 같은 큰 네트워크를 학습 시킬 때에는 학습 속도에 치명적인 영향을 준다. <br />\n",
    "그래서 AlexNet에서는 활성화 함수로 ReLU를 사용하였다. ReLU는 학습 속도가 좋고 backpropagation의 결과도 매우 단순하다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/7.png\" width=700 />\n",
    "<img src=\"./Images/8.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 속도가 sigmoid나 tanh를 사용했을 때에 비하여 6배 정도 빨라지는 것을 볼 수 있다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CNN의 구조에서 일반적으로 pooling은 convolution을 통해 얻은 feature map의 크기를 줄이기 위한 용도로 사용되며, average pooling 또는 max pooling이 존재한다. <br />\n",
    "Average pooling은 pooling window 내에 있는 픽셀 값들의 평균을 취하는 방식이고, Max pooling은 window에서 최대값을 갖는 픽셀을 취하는 방식이다. <br />\n",
    "Max pooling은 average pooling에 비해 연산량이 더 많지만, 최대 크기를 갖는 자극만을 전달한다는 생물학적 특징의 관점에서 보면 더 낫다고 볼 수 있다. <br />\n",
    "LeNet-5에서는 average pooling 방식을 사용하였지만 AlexNet에서는 max pooling을 사용하였다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./Images/9.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "위 그림의 화살표 영역이 pooling 레이어에 해당한다. 일반적으로는 pooling을 할 때 겹치는 부분이 없게 하는 것이 일반적이다. <br /> \n",
    "Pooling window의 크기는 주로 2x2를 사용하고 이 때 만약 stride로 2를 사용하면 출력의 크기는 가로/세로가 각각 1/2로 줄어들게 된다. <br />\n",
    "하지만 AlexNet은 2x2 window 대신 3x3 window를 사용하고 stride로 2를 사용하는 over pooling 방식을 사용하였다. <br />\n",
    "이 over lapped pooling 방식을 통해 top-1과 top-5의 error rates를 각각 0.4%와 0.3% 줄일 수 있었고 과적합에 빠질 가능성도 더 줄일 수 있다고 논문에서 주장하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Local Response Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활성화 함수로 sigmoid나 tanh를 사용하는 것 보다 ReLU를 쓰게 되면, 학습에 걸리는 시간을 줄일 수 있고 backpropagation이 간단해진다. <br />\n",
    "Sigmoid나 tanh의 경우 뉴런이 포화되는 구간이 있기 때문에, 입력에 대하여 정규화(normalization)을 수행한다. <br />\n",
    "이 때, ReLU를 사용하면 입력의 정규화(normalization)이 필요없다는 또다른 장점이 있다. <br />\n",
    "하지만 출력의 경우는 입력이 0이상인 경우 입력에 비례하여 그대로 증가하게 된다. <br />\n",
    "따라서 여러 feature-map에서의 결과에 대하여 normalization을 하면 생물학적 뉴런에서의 lateral inhibition(강한 자극이 주변의 약한 자극이 전달되는 것을 막는 효과)과 <br />\n",
    "같은 효과를 얻을 수 있기 때문에 generalization 관점에서 더 좋아지게 된다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/10.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet에서는 첫 번째와 두 번째의 convolution을 거친 결과에 대하여 ReLU를 수행하고, max pooling을 수행하기에 앞서 response normalization을 수행하였다. <br />\n",
    "이를 통해 top-1과 top-5의 error rates를 각각 1.4%와 1.2%만큼 개선하였다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet의 파라미터의 갯수는 60 millions 수준으로 매우 많기 때문에 과적합 문제가 발생할 수 있다. <br />\n",
    "이 문제에 대한 해결책으로 학습 이미지의 수를 늘리기 위한 data augmentation과 네트워크의 일부를 생략하여 학습을 진행하는 dropout 기법을 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합 문제를 해결하기위해 학습에 사용할 데이터의 양을 늘리는 것이 해결책이 될 수 있다. <br />\n",
    "그러나 학습 데이터를 늘리는 것은 쉽지 않으며, 학습 데이터가 늘어나면 학습 시간이 길어지기 때문에 효율성에 문제가 발생할 수 있음을 염두에 두어야 한다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet에서는 학습 데이터를 늘리기 위해 2가지 방법을 사용한다. <br />\n",
    "(GPU에서 이전 이미지(학습 데이터)를 이용하여 학습하고 있는 동안, CPU에서 이미지를 늘리기 때문에 따로 data augmentation을 통해 증가한 이미지들을 저장할 필요가 없다) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 방법은 ILSVRC의 256x256 크기의 원 이미지로부터 무작위로 224x224 크기의 이미지를 취하는 것이다. <br />\n",
    "이렇게 되면, 1장의 학습 이미지로 부터 2048의 다른 이미지들을 얻을 수 있다. <br />\n",
    "테스트를 할 때는, 5개의 224x224 크기의 이미지(상하 좌우 코너 및 중앙)와 이것들을 수평으로 반전한 이미지 5개, 총 10개의 이미지로부터 softmax 출력의 평균을 사용한다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/11.png\" width=500 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 방법은 각 학습 이미지들로부터 RGB 채널의 값을 변화시키는 것이다. <br />\n",
    "이를 위하여 학습 이미지의 RGB 픽셀 값에 대하여 주성분 분석(PCA)를 수행하였으며, 여기에 평균은 0, 표준편차는 0.1의 크기를 갖는 랜덤 변수를 곱하고 <br />\n",
    "이것을 원래 픽셀 값에 더해주는 방식으로 컬러 채널의 값을 바꾸어 다양한 이미지들을 얻게 되었다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/12.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 data augmentation을 통하여 과적합을 줄이고 top-1 error rates를 1%이상 줄일 수 있게 되었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분의 CNN 아키텍처에서는 dropout을 적용하여 학습 시간을 단축시키고 과적합 문제를 해결한다. <br />\n",
    "Dropout은 voting 효과 및 co-adaptation을 피하는 효과를 얻을 수 있다. <br />\n",
    "아래의 그림은 Hinton의 논문에서 dropout을 hidden 레이어에 대하서만 적용할 때와 입력 레이어와 hidden 레이어 양쪽 모두에 적용했을 때의 결과를 비교한 것이다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/13.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout은 FC 레이어에 대하여 행하기 때문에 AlexNet에서는 FC 레이어의 처음 2개 레이어에 대해서만 적용을 한다. <br />\n",
    "또한 dropout의 비율은 0.5%를 사용하였다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CF) Why GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN을 이용하여 좋은 결과를 내려면, 엄청난 학습 데이터를 필요로 한다. <br />\n",
    "최근의 Deep CNN은 크게 2개로 구성되어 있다. <br />\n",
    "- 전체 연산량의 90~95%를 차지하지만, 파라미터의 갯수는 5%정도인 Conv 레이어\n",
    "- 전체 연산량의 5~10%를 차지하지만, 파라미터의 갯수는 95%정도인 FC 레이어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서, Conv 레이어는 입력 이미지에 대하여 픽셀의 위치를 옮겨가면서 반복적으로 행렬 곱 연산을 수행하고, 여러 개의 입력 feature map으로부터 동일한 파라미터를 갖는 <br />\n",
    "convolution filter(kernel) 연산을 수행하야 하기 때문에 아주 좋은 병렬적인 특징을 갖는다. <br />\n",
    "CNN의 레이어에 따른 병렬성을 구별하면 아래의 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/14.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv 레이어에서는 여러 개의 입력 feature map으로부터 여러 개의 convolution 연산을 수행하기 때문에 높은 수준의 data parallelism이 존재한다. <br />\n",
    "Convolution 연산 하나만 놓고 보더라도 행렬 곱 연산을 수행할 때 행렬의 여러 component들에 대하여 연산 장치만 충분하다면 동시에 개별 곱을 구하여 연산을 더 효과적으로 할 수 있다. <br />\n",
    "또한, low-level 연산 parallelism도 존재하며 입력 이미지의 크기가 커지거나 convolution kernel의 크기가 커지면 연산의 수는 기하급수적으로 증가하게 된다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet에서의 GPU활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet에서는 2개의 GPU를 사용하였다. 개발 당시 사용한 GTX580dms 3GB의 메모리를 가지고 있었고, 메모리 크기 때문에 CNN의 구조에 제약이 있을 수 밖에 없었다. <br />\n",
    "AlexNet에서는 GPU를 위/아래로 나누어 사용하는 방식을 사용했지만 이후 연구들에서 이런 구조는 거의 쓰이지 않는다. <br />\n",
    "아래의 그림은 AlexNet의 구조를 GPU 관점에서 본 것이다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/15.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU의 갯수나 메모리의 크기를 고려하지 않고 아키텍처를 결정한다면 첫 번째 Conv 레이어에서 1개의 GPU에는 color와 무관한 48개의 feature map을 추출하고 <br />\n",
    "다른 GPU에서는 color와 관련된 48개의 feature map을 추출하는 등의 제한을 두지 않았을 것이다. <br />\n",
    "또한 inter GPU와 intra GPU connection 같은 것들을 고려하지 않고 아키텍처를 설계하였다면 더 좋은 결과가 나왔으리라 예측해 볼 수 있다. <br />\n",
    "AlexNet의 논문에서는 2개의 GPU를 사용하여 1개의 GPU를 사용했을 때 보다 top-1과 top-5의 error rates를 각각 1.7%와 1.2% 줄일 수 있었다고 주장하고있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet의 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet의 결과를 보면 상당히 괜찮은 것을 알 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/16.png\" width=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림의 올바른 결과는 그림 바로 밑에 적혀있고, 그 밑에 있는 5개의 후보는 AlexNet이 추정한 top-5이다. <br />\n",
    "Mite(진드기)는 한 쪽으로 치우쳐저 있어도 잘 구별을 하는 것을 볼 수 있으며, leopard에 대한 top-5도 어느정도 비슷하게 보일만 한 것들을 추정하고 있다. <br />\n",
    "추정이 틀린 경우에도 중앙에 있는 것들을 어떻게 볼 것인지에 따라 충분히 추정 가능한 답을 했음을 알 수 있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 결과가 SIFT(Scale Invariant Feature Transform)과 같은 feature extractor를 사용하지 않고, 단순히 CNN의 학습을 통해서 얻어진 결과라는 점은 매우 고무적이다. <br />\n",
    "이는 CNN이 복잡한 이미지에 대해서도 학습 데이터 셋이 충분하다면, 그리고 좋은 CNN 아키텍처를 설계한다면 충분히 좋은 결과를 낼 수 있다는 가능성을 보여주는 것이다. <br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
