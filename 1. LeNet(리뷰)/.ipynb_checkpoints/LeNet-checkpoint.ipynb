{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN의 시초-\"LeNet5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution neural network라는 개념을 최초로 개발한 사람은 프랑스 출신의 Yann LeCun이다. <br />\n",
    "현재 뉴욕대의 교수로 재직중이며 원래는 우편번호와 수표의 필기체를 인식하기 위한 용도로 개발을 시작하였다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun은 기존의 fully-connected neural netwrok의 한계를 이해하고 이를 개선하기 위한 방법을 고안하였다. <br />\n",
    "Fully-connected neural network의 가장 큰 문제점은 topology(위상)의 변화에 대응하기 어렵다는 것이다. <br />\n",
    "따라서 Yann Lecun은 Local receptive field, Shared weight, Sub-sampling의 개념을 결합하여 CNN(Convolution Neural Network)개념을 고안한다. <br />\n",
    "이후 Yann LeCun은 최초로 개발한 LeNet-1을 발표한다. 이는 LeNet-5의 Pre-model로 볼 수 있으며 크기만 작을 뿐 현재의 LeNet-5의 모습을 거의 갖추고 있다. <br />\n",
    "LeNet-1의 구조는 아래와 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/1.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet1<br /> \n",
    "입력 이미지의 크기는 28x28로 LeNet-5에 비해서 작다. <br />\n",
    "1단계 convolution을 통해 얻는 feature map의 갯수는 4개이고 2단계 convolution을 통해 얻는 feature map의 크기는 12개 이다. <br />\n",
    "여기에서 sub-sampling을 적용하여 feature map의 크기를 줄인다던지, 여러 단계의 convolution을 거치면서 작아진 feature map에서 좀 더 global한 feature들을 얻는다던지, <br />\n",
    "의미 있는 global feature들을 얻은 후 이를 입력으로 하여 fully-connected neural network를 classifier로 사용한다던지 하는 점은 LeNet-5와 동일하다. <br />\n",
    "여기에서 5x5 convolution kernel을 통해 local receptive field의 개념을 적용하였고, 전체 이미지에 대해서 같은 kernel을 적용함으로서 shared weight 개념이 적용되었으며, <br /> \n",
    "가장 큰 activation을 취하기 위하여 max pooling을 적용함으로서 sub-sampling을 적용하였다. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann LeCun은 이 구조를 통해 fully-connected network나 다른 머신 러닝 알고리즘을 적용하는것 보다 훨씬 더 나은 성능을 얻게되어 점차 이 구조를 발전시켜 나간다. <br />\n",
    "이후 LeNet-4를 거쳐 최종적으로 LeNet-5를 발표한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-1이 처음 개발되었을 때에는 컴퓨터 자원의 성능이 지금보다 훨씬 떨어졌기 때문에 파라미터의 수가 작을 수 밖에 없었다. <br />\n",
    "이후 하드웨어 성능의 발전에 따라 입력 이미지의 크기 및 convolution kernel의 갯수가 증가하고 fully-connected layer의 크기도 커지는 방향으로 연구 흐름이 이어지게 되었다. <br />\n",
    "LeNet-5의 구조는 아래 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-1의 구조와 비교를 해보면 구조는 상당히 유사하고 단지 크기만 달라졌다는 것을 알 수 있다. <br />\n",
    "LeNet-1에서는 16x16의 크기로 샘플 이미지의 크기를 줄인 후 그것을 28x28 크기의 중앙에 위치하도록 하였지만, <br />\n",
    "LeNet-5에서는 MNIST의 28x28 테스트 이미지를 32x32 크기의 중앙에 위치시켜 처리를 하였다. <br />\n",
    "좀 더 큰 크기의 이미지를을 사용하기 때문에 down-size의 이미지에서보다 더 디테일에 대한 고려가 많아지고 그 결과는 성능의 향상으로 이어지게 되었다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LeNet-1의 경우 약 0.1 millions 정도의 multiply와 add가 필요하지만, 파라미터의 숫자는 3000개 이하로 작다. <br />\n",
    "이는 20x20 크기의 이미지를 입력으로 받고, 300개의 hidden unit을 갖는 400-300-10 fully-connected neural network에서 파라미터의 갯수가 <br /> \n",
    "0.12 millions 이상인 것에 비해 훨씬 작다. <br />\n",
    "실제 망을 통한 학습의 결과도 fully-connected-neural network를 통한 학습 결과보다 LeNet-1이 훨씬 더 좋다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "LeNet-5는 성능 향상을 위해, LeNet-1보다 큰 망을 설계하였다. <br />\n",
    "전체적으로 0.34 millions의 connections가 있으며, 파라미터의 갯수도 약 0.06 millions 이다. 하지만 성능면에서는 훨씬 향샹된 결과를 보여준다. <br />\n",
    "실제로 이 논문에서 여러 알고리즘을 비교한 결과를 보면 fully-connected neural network에 비해 LeNet-1의 성능이 훨씬 뛰어나고 <br />\n",
    "LeNet-5의 결과는 이보다 더 좋다는 것을 알 수 있다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 표에서 최고의 결과를 보인 Boosted LeNet-4는 LeNet-4에 대하여 3가지 다른 방법으로 학습을 실시한다. <br />\n",
    "결과적으로 인위적인 distortion을 통해 training data가 많아지는 것과 같은 효과를 얻게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/3.png\" width=700 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5의 구조를 좀 더 상세히 살펴보면, 구조를 나타내는 그림에는 Cx와 Sx 및 Fx가 나온다. <br />\n",
    "여기서 C는 convolution, S는 sub-sampling, F는 fully-connected layer를 의미하며, 대문자 알파벳 다음에 오는 소문자 x는 layer의 번호를 의미한다. <br />\n",
    "즉, C1은 첫 번째 레이어이고 convolution을 수행하는 레이어이다. F6는 여섯 번째 레이어이고 fully-connected neural network 이다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5의 구조는 총 3개의 conv 레이어와 2개의 sub-sampling 레이어 및 1개의 fully-connected 레이어로 구성되어 있다. <br />\n",
    "Convolution 레이어뒤에 sub-sampling이 이어지면서, 이미지의 크기가 1/4로 줄어들게 된다. <br />\n",
    "C1은 conv 레이어이며 32x32의 이미지를 입력으로 받아 28x28 크기의 feature map을 만들어낸다. <br />\n",
    "5x5 kernel을 사용하고, zero-padding을 사용하지 않기 때문에 boundary 정보가 소실될 수 있다. <br />\n",
    "Conv 레이어의 파라미터들은 사전에 결정되는 것이 아니라 학습을 통해 조정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1 레이어에는 각 convolution kernel에서 총 26(25(5x5 receptive field)+1(bias))의 파라미터가 있고, 이런 kernel들이 6개 있기 때문에 총 156개의 파라미터가 있다. <br />\n",
    "S2는 sub-sampling을 수행하며, 2x2 크기의 filter로부터 average pooling을 수행하기 때문에 결과적으로 28x28 크기의 feature map을 입력으로 받아 <br /> \n",
    "14x14 크기의 출력을 만들어 낸다. 각각의 feature map에 대해 1개의 대응하는 sub-sampling 레이어가 존재한다. <br />\n",
    "Average pooling을 수행하기 때문에 각각의 sub-sampling layer는 2개(weight 1개, bias 1개)의 파라미터를 가지고 있고 따라서 총 파라미터의 갯수는 12개 이다. <br />\n",
    "C3는 C1과 동일한 크기의 5x5 convolution을 수행하며, 14x14 크기의 입력을 받아 10x10 크기의 출력을 만들어 낸다. <br />\n",
    "6개의 feature map들을 convolution 하여 16개의 feature map을 만들어 내는데, 이 때 6개의 모든 입력 feature map이 16개의 모든 출력 feature map에 연결되는 것이 아니라, 아래의 테이블과 같이 선택적으로 입력 feature map을 골라, 출력 feature map에 반영이 될 수 있도록 한다. <br />\n",
    "이렇게하는 이유로는 연산량의 크기를 줄이기 위한것도 있지만, 결정적으로는 연결의 대칭성을 깸으로서, <br /> \n",
    "처음 convolution으로부터 얻어진 6개의 low-level feature가 서로 다른 조합으로 섞이면서, 이것이 global feature로 나타나기를 기대하기 때문이다. <br />\n",
    "이 단계에서 파라미터의 총 갯수는 1,516개 이다. 이는 25(kernel)x60(S2의 feature map과 C3의 Convolution레이어 사이의 연결)+16(bias)의 결과이다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=600 />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S4는 S2와 마찬가지로 sub-sampling 단계이며, 10x10 크기의 feature map을 받아 5x5의 feature map을 만든다. 이 단계의 파라미터의 갯수는 32(2x16)이다. <br />\n",
    "C5의 단계는 16개의 5x5 feature map을 받아, 5x5 크기의 kernel을 사용하여 convolution을 수행하기 때문에, 출력은 1x1 크기의 feature map으로 만들어진다. <br />\n",
    "결과로 총 120개의 feature map을 생성하고 이들을 fully-connected의 형태로 연결한다. <br /> \n",
    "이전 단계에서 얻어진 16개의 feature map을 convolution을 거치면서 다시 전체적으로 섞이는 효과를 내게된다. <br />\n",
    "F6은 fully-connected이며 C5의 결과를 84개의 unit에 연결시킨다. 이 단계에서 파라미터의 갯수는 (120+1(bias))x84=10,164가 된다. <br />\n",
    "입력 이미지에 대해 각각의 단계별 feature map들을 시각화 시키면 아래의 그림과 같다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단계별 시각화를 보면, LeNet-5의 각각의 레이어에서 어떤 출력이 나오는지 알 수 있으며, topology의 변화나 노이즈에 대한 내성이 상당히 강함을 알 수 있다.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
