{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Classification with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 ImageNet LSVRC-2010 contest의 1.2 million 고해상도 이미지들을 1000개의 서로 다른 클래스들로 <br />\n",
    "분류하기 위해 크고, 깊은 컨볼루션 네트워크를 학습시켰다. <br />\n",
    "테스트 데이터에 대하여, 우리는 top-1 과 top-5 error rates에 대하여 각각 37.5%, 17.5%를 달성하였고, <br />\n",
    "이는 이전의 최신 기술보다 훨씬 더 좋은 결과를 보여주는 것이다. <br />\n",
    "60 million개의 파라미터들과 650,000개의 뉴런들을 가지고 있는 이 뉴럴 네트워크는 5개의 Conv 레이어들로 구성 되어있고 <br /> \n",
    "이들 중 몇 개는 뒤이어 max-pooling 레이어들이 있다. <br /> \n",
    "그리고 최종적으로 1000개의 softmax 결과를 가지도록하는 세 개의 fully-connected 레이어로 구성되어 있다. <br />\n",
    "학습을 더 빠르게 하기 위해, 우리는 포화되지않은 뉴런들과 convolution 연산에 매우 효율적인 GPU를 사용하였다. <br />\n",
    "Fully-connected 레이어들에서의 과적합을 줄이기 위해, <br /> \n",
    "우리는 dropout이라고 불리는 최근에 개발된 정규화(regularization) 방법을 적용하였고 이는 매우 효과적임을 보였다. <br /> \n",
    "우리는 또한 이 모델을 가지고 ILSVRC-2012 대회에도 출전하였고 <br /> \n",
    "top-5 test에서 15.3%의 error rate를 가지고 우승을 하였다. 2등은 26.2%의 error rate를 가졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물체 인식을 위한 최근의 접근법들은 머신러닝 방법들을 필수적으로 사용한다. <br />\n",
    "그들의 성능을 향상시키기 위해서, 우리는 더 많은 데이터 셋을 수집해야 하고, 더 강력한 모델을 학습해야 하며 <br /> \n",
    "과적합을 방지하기 위한 더 나은 기술들을 사용해야 한다. <br />\n",
    "최근까지, 라벨화된 이미지들의 데이터 셋이 상대적으로 작았다. <br />\n",
    "on the order of tens of thousands of images(e.g. NORB, Caltech-101/256 and CIFAR-10/100). <br />\n",
    "간단한 인식 task는 이정도 사이즈의 데이터 셋을 가지고도 꽤 잘 해결되었다. <br />\n",
    "특히 만약에 이들이 라벨을 보존한 상태에서의 변형을 통해 증가된 경우는 더 그렇다. <br />\n",
    "예를 들어, MINST digit 인식 task에서 최근 가장 좋은 error rate(<0.3%)는 인간의 수행 능력에 근접한다. <br />\n",
    "그러나 현실 상황에서의 물체 인식은 상당한 변동성을 보여준다. <br /> \n",
    "따라서 그들을 인식하기 위한 학습에는 필연적으로 훨씬 더 많은 학습 데이터 셋을 사용해야 한다. <br />\n",
    "작은 이미지 데이터 셋에 대한 단점은 널리 인식되고 있으나 비교적 최근에 이르러서야 수많은 이미지의 라벨화된 데이터 셋을 모을 수 있게 되었다. <br />\n",
    "새로운 더 커진 데이터 셋들 중에는 LabelMe(수많은 Fully-segmented된 이미지로 구성됨), <br /> \n",
    "ImageNet(15millio labeled high-resolution 이미지들에 대하여 22,000개의 카테고리로 구성됨)이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millions의 이미지들로부터 thousands의 물체들을 학습하려면, 우리는 큰 학습 용량을 가진 모델이 필요하다. <br />\n",
    "그러나 물체 인식 task의 거대한 복잡성은 이 문제가 ImageNet만큼 큰 데이터 셋에 의해서도 구체화 될 수 없음을 의미한다. <br />\n",
    "따라서 우리의 모델은 우리가 가지지 못한 모든 데이터에 대해서도 보상할 수 있는 많은 선행 지식 또한 가져야 한다. <br />\n",
    "컨볼루션 뉴럴 네트워크(CNNs)는 그런 종류의 모델을 구성한다. <br />\n",
    "그들의 용량은 그들의 깊이와 폭을 변화시킴으로써 조정가능하고, 그들은 또한 이미지들의 특성에 대하여 강하고 가장 알맞은 가정을 만들 수 있다. <br /> \n",
    "(즉, 통계와 픽셀 의존성의 지역성의 안정성) <br />\n",
    "그러므로, 비슷한 사이즈 레이어들로 구성된 표준 feedforward 뉴럴 네트워크와 비교하면, CNNs는 훨씬 더 작은 수의 파라미터들과 <br />\n",
    "연결들을 가지고 있고 따라서 이들은 학습시키기 훨씬 쉽다. 반면에 그들의 이론적 최대 성능은 단지 조금 나빠질 뿐이다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CNNs의 매력적인 qualities와 그들의 local architecture의 상대적 효율성에도 불구하고, <br /> \n",
    "그들을 여전히 고해상도 이미지에 대규모로 적용하는기에는 엄청나게 expensive 하다. <br />\n",
    "운좋게도, 2D 컨볼루션의 고도로 최적화된 구현과 결합하여, 현재의 GPU들은 흥미롭게도 큰 CNNs의 학습을 촉진하기에 충분히 powerful하다. <br />\n",
    "그리고 ImageNet같은 최근의 데이터 셋들은 심각한 과적합 없이 이런 모델들을 학습할 충분히 라벨화된 예제들을 포함하고 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 논문의 구체적인 공헌은 다음과 같다. 우리는 가장 큰 컨볼루션 뉴럴 네트워크들을 ILSVRC-2010과 ILSVRC-2012 대회에서 사용된 <br />\n",
    "ImageNet의 subset을 지금까지 학습시켰고 지금까지 이 데이터 셋들에 대해서 보고된 가장 좋은 결과를 성취하고 있다. <br />\n",
    "우리는 2D 컨볼루션의 고도로 최적화된 GPU 구현을 기술하였고 모든 다른 연산들은 학습하는 컨볼루션 뉴럴 네트워크에 내재되어 있다. <br />\n",
    "이것은 공개적으로 공개되어 있다. <br />\n",
    "우리의 네트워크는 많은 새로운 일반적이지 않은 특징들을 가지고 있고 이들은 네트워크의 성능을 향상시키고 학습 시간을 단축시킨다. <br /> \n",
    "이는 Section3에 자세하게 서술되어있다. <br /> \n",
    "우리 네트워크의 사이즈는 1.2 million의 라벨화된 학습 예제들을 사용했음에도 불구하고 과적합을 중요한 문제로 만들었다. <br />\n",
    "따라서 우리는 과적합을 방지하기 위해 몇몇 효과적인 기술을 사용했다. 이는 Section4에 자세하게 기술되어있다. <br />\n",
    "우리의 최종적인 네트워크는 5개의 convluional 레이어들과 3개의 fully-connected 레이어들을 포함하고 있다. <br />\n",
    "그리고 이 깊이는 매우 중요해보인다. 우리는 어떤 Conv 레이어(각각은 전체 모델의 파라미터들의 1%를 넘지 않음)를 삭제하는 것도 더 좋지않은 성능을 야기한다는 것을 발견하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국, 네트워크의 사이즈는 최근 GPU들의 가능한 메모리의 크기와 우리가 감내할 수 있는 학습시간의 양에 의해 주로 제한된다. <br />\n",
    "우리의 네트워크는 두개의 GTX 580 3GB GPU들을 사용하여 5~6일 정도 소요되었다. <br />\n",
    "우리의 모든 실험들은 우리의 결과들이 더 빠른 GPU들과 더 큰 데이터 셋이 가능해짐으로서 더 향상될 수 있다는 것을 말해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet은 대략적으로 15 million의 라벨화된 고해상도 이미지들에 대하여 이들이 22,000개의 카테고리들에 속한 데이터 셋이다. <br />\n",
    "이 이미지들은 웹으로부터 수집되어 Ama- zon’s Mechanical Turk crowd-sourcing tool을 사용하여 인간 labeler들에 의해 라벨화되었다. <br />\n",
    "2010년도에 시작하여, Pascal Visual Object Challenge의 부분으로서, <br />\n",
    "the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)라 불리는 대회가 매년 열린다. <br />\n",
    "ILSVRC는 1000개의 카테고리에 약 1000개의 이미지가 있는 ImageNet subset을 사용한다. <br />\n",
    "모두, 약 1.2 million의 교육 이미지, 50,000 개의 유효성 검사 이미지, 150,000 개의 테스트 이미지가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2010은 테스트 셋 레이블들이 사용가능한 유일한 버전의 ILSVRC 이다. 그래서 이것은 우리가 대부분의 실험을 수행 한 버전이다. <br />\n",
    "우리는 또한 우리의 모델로 ILSVRC-2012 대회에 참가하였기 때문에, Section6에서 이 버전의 데이터 셋에 대한 결과 또한 보고할 것이다. <br />\n",
    "ImageNet에 대하여, 두 가지 error rates들을 보고하는 것이 일반적이다. <br /> \n",
    "(top-1과 top-5) 여기서 top-5의 error rates는 모델에 의해 가장 가능성이 있다고 여겨지는 5 개의 레이블 중에서 <br />\n",
    "올바른 레이블이 없는 테스트 이미지들의 비율이다 . <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet은 다양한 고해상도 이미지들로 구성되어있다. 반면 우리의 시스템을 일정한 입력 차원성을 필요로 한다. <br />\n",
    "그러므로, 우리는 이미지들을 고정된 256x256의 해상도로 만들기위해 다운 샘플링을 한다. <br />\n",
    "직사각형 이미지가 주어지고, 우리는 먼저 짧은 쪽의 길이가 256이 되도록 이미지의 크기를 조정했다. <br /> \n",
    "그런 다음 결과 이미지로부터 중앙 256×256 patch를 잘라 냈다. <br /> \n",
    "우리는 이미지들을 각 픽셀로부터 학습 셋에 대한 평균 activity를 뺀것을 제외하고는 다른 방법으로는 전처리하지 않았다. <br />\n",
    "따라서 우리는 우리의 네트워크를 픽셀의 centered raw RGB 값에 대하여 학습하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리 네트워크의 아키텍처는 Figure 2에 요약되어있다. 이는 8개의 레이어로서 5개의 컨볼루션 레이어와 3개의 fully-connected 레이어를 포함한다. <br />\n",
    "아래에, 우리는 우리 네트워크의 아키텍처의 몇몇 새롭거나 일반적이지 않은 특징을 설명한다. <br />\n",
    "Section 3.1-3.4는 그들의 중요도에 대한 우리의 평가에 따라 정렬되며, 가장 첫 번째는 가장 중요한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ReLU Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴런의 출력 $f$를 이것의 입력 $x$의 함수로 모델링하는 표준 방법은 $f(x)=tanh(x)$ 또는 $f(x)={ (1+{ e }^{ -x }) }^{ -1 }$이다. <br />\n",
    "그라디언트 디센트의 학습 관점에서, 이 포화되는 비선형성은 포화되지 않는 비선형성 $f=max(0,x)$보다 훨씬 더 느리다. <br />\n",
    "Nair과 Hinton에 따르면, 이 비선형성을 가진 뉴런을 Reticified Linear Units(ReLUs)라 부른다. <br />\n",
    "ReLUs를 사용한 Deep ConvNet은 동일한 네트워크에서 활성화 함수만 $tanh$ units를 사용한 것 보다 몇 배 더 빠르다. <br />\n",
    "이는 Figure 1에 나타나있다. <br /> \n",
    "이는 특정 4-layer ConvNet에 대해 CIFAR-10 데이터 셋에서 25%의  training error에 도달하는데 필요한 반복 횟수를 보여준다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
