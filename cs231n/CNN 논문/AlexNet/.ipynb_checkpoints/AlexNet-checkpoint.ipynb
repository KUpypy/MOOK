{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Classification with Deep Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 ImageNet LSVRC-2010 대회의 1.2 million 고해상도 이미지들을 1000개의 서로 다른 클래스들로 <br />\n",
    "분류하기 위해 크고, 깊은 컨볼루션 네트워크를 학습시켰다. <br />\n",
    "테스트 데이터에 대하여, 우리는 top-1과 top-5 error rates을 각각 37.5%, 17.5% 달성하였고, <br />\n",
    "이는 이전의 최신 기술보다 훨씬 더 좋은 결과를 보여주는 것이다. <br />\n",
    "60 million개의 파라미터들과 650,000개의 뉴런들을 가지고 있는 이 뉴럴 네트워크는 5개의 Conv 레이어들로 구성 되어있고 <br /> \n",
    "이들 중 몇 개는 뒤이어 max-pooling 레이어들이 있다. <br /> \n",
    "그리고 마지막에는 1000개의 softmax 결과를 가지도록 하는 세 개의 fully-connected 레이어로 구성되어 있다. <br />\n",
    "학습을 더 빠르게 하기 위해, 우리는 포화되지않은 뉴런들과 convolution 연산에 매우 효율적인 GPU를 사용하였다. <br />\n",
    "Fully-connected 레이어들에서의 과적합을 줄이기 위해, <br /> \n",
    "우리는 dropout이라고 불리는 최근에 개발된 정규화(regularization) 방법을 적용하였고 이는 매우 효과적임을 확인하였다. <br /> \n",
    "우리는 또한 이 모델을 가지고 ILSVRC-2012 대회에도 출전하였고 <br /> \n",
    "top-5 test에서 15.3%의 error rate를 가지고 우승을 하였다. 2등은 26.2%의 error rate를 달성했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물체 인식을 위한 최근의 접근법들은 머신러닝 방법들을 필수적으로 사용한다. <br />\n",
    "그들의 성능을 향상시키기 위해서, 우리는 더 많은 데이터 셋을 수집해야 하고, 더 강력한 모델을 학습해야 하며 <br /> \n",
    "과적합을 방지하기 위한 더 나은 기술들을 사용해야 한다. <br />\n",
    "최근까지, 라벨화된 이미지들의 데이터 셋은 상대적으로 작았다. <br />\n",
    "-on the order of tens of thousands of images(e.g. NORB, Caltech-101/256 and CIFAR-10/100). <br />\n",
    "간단한 인식 task는 이정도 사이즈의 데이터 셋을 가지고도 꽤 잘 해결되었다. <br />\n",
    "특히 만약에 이들이 라벨을 보존한 상태에서의 변형을 통해 증가된 경우는 더 그렇다. <br />\n",
    "예를 들어, MINST digit 인식 task에서 최근 가장 좋은 error rate(0.3% 미만)는 인간의 수행 능력에 근접한다. <br />\n",
    "그러나 현실 상황에서의 물체 인식은 상당한 변동성을 보여준다. <br /> \n",
    "따라서 그들을 인식하기 위한 학습에는 필연적으로 훨씬 더 많은 학습 데이터 셋을 사용해야 한다. <br />\n",
    "작은 이미지 데이터 셋에 대한 단점은 널리 인식되고 있으나 비교적 최근에 이르러서야 수많은 이미지의 라벨화된 데이터 셋을 모을 수 있게 되었다. <br />\n",
    "새로운 더 커진 데이터 셋들 중에는 LabelMe(수많은 Fully-segmented된 이미지로 구성됨), <br /> \n",
    "ImageNet(15millio labeled high-resolution 이미지들에 대하여 22,000개의 카테고리로 구성됨)이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Millions의 이미지들로부터 thousands의 물체들을 학습하려면, 우리는 큰 학습 용량을 가진 모델이 필요하다. <br />\n",
    "그러나 물체 인식 task의 거대한 복잡성은 이 문제가 ImageNet만큼 큰 데이터 셋에 의해서도 구체화 될 수 없음을 의미한다. <br />\n",
    "따라서 우리의 모델은 우리가 가지지 못한 모든 데이터에 대해서도 보상할 수 있는 많은 선행 지식 또한 가져야 한다. <br />\n",
    "컨볼루션 뉴럴 네트워크(CNNs)는 그런 종류의 모델을 구성한다. <br />\n",
    "그들의 용량은 그들의 깊이와 폭을 변화시킴으로써 조정가능하고, 그들은 또한 이미지들의 특성에 대하여 강하고 가장 알맞은 가정을 만들 수 있다. <br /> \n",
    "(즉, 통계와 픽셀 의존성의 지역성의 안정성) <br />\n",
    "그러므로, 비슷한 사이즈 레이어들로 구성된 표준 feedforward 뉴럴 네트워크와 비교하면, CNNs는 훨씬 더 작은 수의 파라미터들과 <br />\n",
    "연결들을 가지고 있고 따라서 이들은 학습시키기 훨씬 쉽다. 반면에 그들의 이론적 최대 성능은 단지 조금 나빠질 뿐이다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CNNs의 매력적인 qualities와 그들의 local architecture의 상대적 효율성에도 불구하고, <br /> \n",
    "그들을 여전히 고해상도 이미지에 대규모로 적용하는기에는 엄청나게 expensive 하다. <br />\n",
    "운좋게도, 2D 컨볼루션의 고도로 최적화된 구현과 결합하여, 현재의 GPU들은 흥미롭게도 큰 CNNs의 학습을 촉진하기에 충분히 powerful하다. <br />\n",
    "그리고 ImageNet같은 최근의 데이터 셋들은 심각한 과적합 없이 이런 모델들을 학습할 충분히 라벨화된 예제들을 포함하고 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 논문의 구체적인 공헌은 다음과 같다. 우리는 가장 큰 컨볼루션 뉴럴 네트워크들을 ILSVRC-2010과 ILSVRC-2012 대회에서 사용된 <br />\n",
    "ImageNet의 subset을 지금까지 학습시켰고 지금까지 이 데이터 셋들에 대해서 보고된 가장 좋은 결과를 성취하고 있다. <br />\n",
    "우리는 2D 컨볼루션의 고도로 최적화된 GPU 구현을 기술하였고 모든 다른 연산들은 학습하는 컨볼루션 뉴럴 네트워크에 내재되어 있다. <br />\n",
    "이것은 공개적으로 공개되어 있다. (1) <br />\n",
    "우리의 네트워크는 많은 새로운 일반적이지 않은 특징들을 가지고 있고 이들은 네트워크의 성능을 향상시키고 학습 시간을 단축시킨다. <br /> \n",
    "이는 Section3에 자세하게 서술되어있다. <br /> \n",
    "우리 네트워크의 사이즈는 1.2 million의 라벨화된 학습 예제들을 사용했음에도 불구하고 과적합을 중요한 문제로 만들었다. <br />\n",
    "따라서 우리는 과적합을 방지하기 위해 몇몇 효과적인 기술을 사용했다. 이는 Section4에 자세하게 기술되어있다. <br />\n",
    "우리의 최종적인 네트워크는 5개의 convluional 레이어들과 3개의 fully-connected 레이어들을 포함하고 있다. <br />\n",
    "그리고 이 깊이는 매우 중요해보인다. 우리는 어떤 Conv 레이어(각각은 전체 모델의 파라미터들의 1%를 넘지 않음)를 삭제하는 것도 더 좋지않은 성능을 야기한다는 것을 발견하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국, 네트워크의 사이즈는 최근 GPU들의 가능한 메모리의 크기와 우리가 감내할 수 있는 학습시간의 양에 의해 주로 제한된다. <br />\n",
    "우리의 네트워크는 두개의 GTX 580 3GB GPU들을 사용하여 5~6일 정도 소요되었다. <br />\n",
    "우리의 모든 실험들은 우리의 결과들이 더 빠른 GPU들과 더 큰 데이터 셋이 가능해짐으로서 더 향상될 수 있다는 것을 말해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1) [ http://code.google.com/p/cuda-convnet/]( http://code.google.com/p/cuda-convnet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet은 대략적으로 15 million의 라벨화된 고해상도 이미지들에 대하여 이들이 22,000개의 카테고리들에 속한 데이터 셋이다. <br />\n",
    "이 이미지들은 웹으로부터 수집되어 Ama- zon’s Mechanical Turk crowd-sourcing tool을 사용하여 인간 labeler들에 의해 라벨화되었다. <br />\n",
    "2010년도에 시작하여, Pascal Visual Object Challenge의 부분으로서, <br />\n",
    "the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC)라 불리는 대회가 매년 열린다. <br />\n",
    "ILSVRC는 1000개의 카테고리에 약 1000개의 이미지가 있는 ImageNet subset을 사용한다. <br />\n",
    "모두, 약 1.2 million의 교육 이미지, 50,000 개의 유효성 검사 이미지, 150,000 개의 테스트 이미지가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2010은 테스트 셋 레이블들이 사용가능한 유일한 버전의 ILSVRC 이다. 그래서 이것은 우리가 대부분의 실험을 수행 한 버전이다. <br />\n",
    "우리는 또한 우리의 모델로 ILSVRC-2012 대회에 참가하였기 때문에, Section6에서 이 버전의 데이터 셋에 대한 결과 또한 보고할 것이다. <br />\n",
    "ImageNet에 대하여, 두 가지 error rates들을 보고하는 것이 일반적이다. <br /> \n",
    "(top-1과 top-5) 여기서 top-5의 error rates는 모델에 의해 가장 가능성이 있다고 여겨지는 5 개의 레이블 중에서 <br />\n",
    "올바른 레이블이 없는 테스트 이미지들의 비율이다 . <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet은 다양한 고해상도 이미지들로 구성되어있다. 반면 우리의 시스템을 일정한 입력 차원성을 필요로 한다. <br />\n",
    "그러므로, 우리는 이미지들을 고정된 256x256의 해상도로 만들기위해 다운 샘플링을 한다. <br />\n",
    "직사각형 이미지가 주어지고, 우리는 먼저 짧은 쪽의 길이가 256이 되도록 이미지의 크기를 조정했다. <br /> \n",
    "그런 다음 결과 이미지로부터 중앙 256×256 patch를 잘라 냈다. <br /> \n",
    "우리는 이미지들을 각 픽셀로부터 학습 셋에 대한 평균 activity를 뺀것을 제외하고는 다른 방법으로는 전처리하지 않았다. <br />\n",
    "따라서 우리는 우리의 네트워크를 픽셀의 centered raw RGB 값에 대하여 학습하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리 네트워크의 아키텍처는 Figure 2에 요약되어있다. <br /> \n",
    "이는 8개의 레이어로서 5개의 컨볼루션 레이어와 3개의 fully-connected 레이어를 포함한다. <br />\n",
    "아래에, 우리는 우리 네트워크의 아키텍처의 몇몇 새롭거나 일반적이지 않은 특징을 설명한다. <br />\n",
    "Section 3.1-3.4는 그들의 중요도에 대한 우리의 평가에 따라 정렬되며, 가장 첫 번째는 가장 중요한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ReLU Nonlinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴런의 출력 $f$를 이것의 입력 $x$의 함수로 모델링하는 표준 방법은 $f(x)=tanh(x)$ 또는 $f(x)={ (1+{ e }^{ -x }) }^{ -1 }$이다. <br />\n",
    "그라디언트 디센트의 학습 관점에서, 이 포화되는 비선형성은 포화되지 않는 비선형성 $f=max(0,x)$보다 훨씬 더 느리다. <br />\n",
    "Nair과 Hinton에 따르면, 이 비선형성을 가진 뉴런을 Reticified Linear Units(ReLUs)라 부른다. <br />\n",
    "ReLUs를 사용한 Deep ConvNet은 동일한 네트워크에서 활성화 함수만 $tanh$ units를 사용한 것 보다 몇 배 더 빠르다. <br />\n",
    "이는 Figure 1에 나타나있다. <br /> \n",
    "이는 특정 4-layer ConvNet에 대해 CIFAR-10 데이터 셋에서 25%의  training error에 도달하는데 필요한 반복 횟수를 보여준다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./Images/1.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure1: <br />\n",
    "ReLUs(굵은 선)을 사용한 4-layers의 컨볼루션 뉴럴 네트워크가 동등한 네트워크에 대하여 활성화 함수만 $tanh$(점 선)로 사용한 네트워크보다 <br /> \n",
    "CIFAR-10에 대하여 training error rate가 25%에 6배 빨리 도달했다. <br />\n",
    "각각의 네트워크에 대한 learning rates는 학습이 가능한 제일 빠르게 독립적으로 선택되었다. <br />\n",
    "어떠한 종류의 정규화(regularization)도 적용되지 않았다. <br />\n",
    "여기서 보여지는 효과의 정도는 네트워크의 아키텍처에 따라 다르다. <br /> \n",
    "그러나 ReLUs를 사용한 네트워크는 동등한 네트워크에 대하여 포화되는 뉴런들을 사용한 네트워크보다 몇 배 더 빠르다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 plot은 만약 우리가 전통적인 포화 뉴런 모델을 사용했다면 <br /> \n",
    "우리가 이 작업을 위해 어떤 큰 뉴럴 네트워크를 실험하지는 못했을 것임을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 CNN의 전통적인 뉴런 모델에 대한 대안을 처음으로 고려하지는 않는다. <br />\n",
    "예를 들면, Jarrett은 비선형성 $f(x)=|tanh(x)|$가 Caltech-101 데이터 셋의 지역 평균 pooling에 따른 <br /> contrast normalization의 유형에 특히 잘 잘동한다고 주장한다. 그러나 이 데이터 셋에서 주된 관심사는 과적합을 방지하는 것이다. <br />\n",
    "따라서 그들이 관찰하는 효과는 ReLUs를 사용할 때 우리가 보고하는 트레이닝 셋에 가속화된 능력과는 다르다. <br />\n",
    "더 빠른 학습은 큰 데이터 셋에서 큰 모델을 학습하는 것의 성능에 큰 영향을 미친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CF) Local contrast normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local contrast normalization (LCN) is a method used to normalize the contrast of an image in a non-linear way. <br /> \n",
    "Instead of performing a global normalization based on the range of values of the entire image, <br /> \n",
    "LCN operates on local patches of the image on a per pixel basis. <br /> \n",
    "This can be done by removing the mean of a neighborhood from a particular pixel <br /> \n",
    "and dividing by the variation of the pixel values. <br /> \n",
    "(This should sound familiar to generating a zero mean and unit variance Gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 Training on Multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 GTX 580 GPU는 3GB 메모리이다. 이는 네트워크 위에서 학습될 수 있는 네트워크의 최대 사이즈를 제한시킨다. <br />\n",
    "1.2 million의 학습 예제는 너무 커서 하나의 GPU에는 적합하지 않은 네트워크를 학습시키는 것으로 나타난다. <br />\n",
    "그러므로 우리는 네트워크를 두개의 GPU에 걸쳐서 spread 하였다. <br /> \n",
    "현재의 GPU들은 특히 호스트 컴퓨터의 메모리를 거치지 않고 서로의 메모리를 직접 읽고 쓸 수 있기 때문에 cross-GPU 병렬에 적합하다. <br />\n",
    "필수불가결하게 채택한 병렬화 계획은 kernels(즉 뉴런들)의 절반을 각 GPU에 할당하고, <br /> \n",
    "하나 추가된 트릭으로: GPUs는 특정 레이어들에서만 통신한다. <br />\n",
    "예를 들어, 레이어 3의 kernels는 레이어 2의 모든 kernel maps에서 입력을 받는다. <br /> \n",
    "그러나 레이어 4의 kernels는 동일한 GPU에 있는 레이어 3의 kernel maps에서만 입력을 받는다. <br />\n",
    "연결의 패턴을 선택하는것은 cross-validation의 문제이지만, 이것은 우리가 계산의 양이 허용 가능한 부분이 될 때까지 <br /> \n",
    "커뮤니케이션의 양을 정확하게 조정할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과로서의 아키텍처는 우리의 columns는 서로 독립적이지 않다는 것만 빼면(see Figure2)\n",
    "Ciresan에 의해 고안된 columnar CNN과 다소 비슷하다. <br />\n",
    "이 방법은 하나의 GPU에서 학습된 각 Conv 레이어의 kernel 개수가 절반인 네트워크에 비해 \n",
    "우리의 top-1과 top-5 error rates를 1.7%와 1.2%만큼 감소시킨다. \n",
    "Two-GPU 네트워크는 one-GPU 네트워크보다 학습 시간이 약간 적다. (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (2) 최종 Conv 레이어에서 one-GPU 네트워크는 실제로 two-GPU의 네트워크와 같은 수의 커널을 가지고 있다. <br />\n",
    "> 이는 네트워크의 대부분의 파라미터가 마지막 Conv 레이어를 입력으로 가지는 <br /> \n",
    "> 첫 번째 fully-connected 레이어에 있기 때문이다. <br />\n",
    "> 따라서 두 네트워크가 대략적으로 같은 수의 파라미터를 가지게 하려면, <br /> \n",
    "> 우리는 최종 Conv 레이어의 크기를 반으로 나누면 안된다. <br /> \n",
    "> 또한 뒤이어 있는 fully-connected 레이어의 크기도 반으로 나누면 안된다. <br />\n",
    "> 그러므로 이 비교는 이것이 two-GPU 네트워크 절반의 사이즈보다 크기 때문에, one-GPU 네트워크에 유리하게 편향된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Local Response Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLUs는 좋은 성질을 가지고 있는데 이는 이들이 포화로부터 그들을 막기위해 입력 정규화(normalization)을 필요로 하지 않는다는 점이다. <br />\n",
    "만약 적어도 몇몇 학습 예제들이 ReLU에 양의 입력을 발생시면, 그 뉴런에서 학습이 일어난다. <br />\n",
    "그러나, 우리는 또한 지역 정규화(normalization) 방법이 일반화(generalization)을 돕는다는 것을 알아냈다. <br />\n",
    "${ a }_{ x,y }^{ i }$는 $(x,y)$의 위치에서 kernel $i$에 의해 계산된 뉴런의 activity를 나타낸다. 그런다음 ReLU 비선형성을 적용한다. <br />\n",
    "response-normalized activity ${ b }_{ x,y }^{ i }$는 다음과 같은 표현식으로 나타난다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/2.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 동일한 공간 위치에서 $n$개의 인접한 kernel maps에 대하여 합이 실행된다. <br />\n",
    "그리고 $N$은 레이어에서 전체 커널의 갯수이다. 물론 kernel maps의 순서는 임의적이며 학습이 시작되기 전에 결정된다. <br />\n",
    "이러한 response normalization같은 것들은 실제 뉴런에서 발견되는 유형에 영향을 받은 lateral inhibition의 한 형태를 구현한 것이다. <br />\n",
    "이는 서로 다른 kernel들을 사용하여 계산된 뉴런 출력들 간의 큰 activities를 위한 경쟁을 창출한다. <br />\n",
    "상수 $k, n, \\alpha$ and $\\beta$는 하이퍼 파라미터이고 이 값들은 validation 셋을 이용하여 결정된다. 우리는 $k=2, n=5, \\alpha={10}^{-4}$ 그리고 $\\beta=0.75$로 사용하였다. <br />\n",
    "우리는 이 정규화(normalization)을 특정 레이어들에서 ReLU 비선형성을 적용하고 난 다음 적용하였다.(see Section 3.5) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 기법은 Jarrett의 local contrast normalization 기법과 닮았다. <br />\n",
    "하지만 우리것은 \"brightness nomalization\"이라고 명명해야 더 맞을 것 같다. <br />\n",
    "왜냐하면 우리는 평균 activity를 빼지 않기 때문이다. <br />\n",
    "Response nomalization은 우리의 top-1과 top-5의 error rates를 각각 1.4%와 1.2%만큼 줄여준다. <br />\n",
    "우리는 또한 CIFAR-10 데이터 셋에 대하여서도 이 기법이 효과적이라는 것을 입증했다. <br />\n",
    "four-레이어 CNN은 정규화(normalization)없이는 13%의 테스트 error rate를 정규화를 하고 나서는 11%의 error rate를 달성했다. (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 코드와 파라미터 파일에 대한 자세한 내용은 [http://code.google.com/p/cuda-convnet/](http://code.google.com/p/cuda-convnet/)에서 제공한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Overlapping Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNS의 풀링 레이어들은 동일한 kernel map에 있는 뉴런들의 이웃하는 그룹의 출력을 요약해준다. <br />\n",
    "전통적으로, 인접한 풀링 units에 의해 요약된 이웃들은 중첩되지 않는다. <br />\n",
    "더 정확히 말하면, 풀링 레이어는 $s$ 픽셀만큼 떨어져있는 풀링 unit들의 격자로 구성되는것으로 생각할 수 있다. <br />\n",
    "각각은 풀링 unit의 위치에 중심을 둔 사이즈 $z×z$의 이웃을 요약한다. <br />\n",
    "만약 $s=z$로 설정하면, 우리는 CNNs에서 일반적으로 사용되는 전통적인 local 풀링을 얻는다. <br />\n",
    "만약 $s<z$로 설정하면 중첩되는 풀링이 된다. 이것은 우리의 네트워크에서 걸쳐서 $s=2$ 및 $z=3$을 사용하는 것이다. <br />\n",
    "이 기법은 중첩하지 않는 기법($s=2, z=2$, 동일한 차수의 출력을 생성)과 비교하여 각각 top-1과 top-5의 error rates를 각각 0.4%와 0.3% 줄인다. <br /> \n",
    "우리는 일반적으로 중첩되는 풀링 모델은 학습하는 과적합을 관찰하기가 좀 더 어렵다는 것을  관찰할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Overall Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 우리 CNN의 전반적인 아키텍처에 대해 서술할 준비가 되었다. <br />\n",
    "Figure 2에 묘사되어있듯이, 네트워크는 가중치들과 함께 8개의 레이어들을 포함한다. <br />\n",
    "처음 5개는 컨볼루셔널 레이어이고 남은 3개의 레이어는 fully-connected이다. <br />\n",
    "마지막 fully-connected 레이어의 출력은 1000개의 클래스 라벨들에 대하여 분포를 생성하는 1000가지 softmax로 이루어진다. <br />\n",
    "우리의 네트워크는 multinomial logistic regression objective을 극대화한다. <br /> \n",
    "이는 예측 분포 아래에서 학습 케이스들의 올바른 라벨의 로그 확률을 따라 평균을 최대화하는것과 동등하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째, 네 번째 그리고 다섯 번째 Conv 레이어들의 kernel들은 동일한 GPU에 있는 이전 레이어의 kernel maps에만 연결된다. <br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: <br />\n",
    "우리 CNN의 구조의 삽화, 명시적으로 two-GPU 사이의 책임의 묘사를 보여준다. <br />\n",
    "하나의 GPU는 그림의 상단에서 layer-parts를 실행하고 다른 하나는 하단에서 layer-parts를 실행한다. <br />\n",
    "GPU는 특정 레이어들 사이에서만 커뮤니케이션한다. <br />\n",
    "네트워크의 입력은 150,528 차원이고 네트워크의 나머지 레이어들에 있는 뉴런의 수는 <br />\n",
    "253,440-186,624-64,896-64,896-43,264- 4096-4096-1000 이다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세 번째 컨볼루션 레이어의 kernel들은 두 번째 레이어의 모든 kernel maps에 연결된다. <br /> \n",
    "fully-connected 레이어의 뉴런들은 이전 레이어의 모든 뉴런들에 연결된다. <br /> \n",
    "Response-normalization 레이어들은 첫 번째와 두 번째 Conv 레이어 뒤에 있다.\n",
    "3.4 절에서 설명하였던 Max-pooling 레이어들은 Response-normalization 레이어들과 다섯 번째 Conv 레이어의 뒤에 있다. <br />\n",
    "ReLU 비선형성은 모든 Conv 레이어 및 fully-connected 레이어의 출력에 적용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 Conv 레이어는 4 픽셀의 stride(이것은 kernel map에서 인접 뉴런의 receptive field 중심 사이의 거리)를 가진 <br />\n",
    "11x11x3 크기의 96개 kernle들로 224×224×3 입력 이미지를 filter 한다. <br />\n",
    "두 번째 Conv 레이어는 첫 번째 Conv 레이어의 (response-normalized되고 풀링된) 출력을 입력으로 취해 <br /> \n",
    "그것을 5×5×48 크기의 256개의 커널로 filter 한다. <br />\n",
    "세 번째와 네 번째 그리고 다섯 번째 Conv 레이어들은 중간에 어떤 풀링이나 정규화(normalization) 레이어 없이 서로 연결되어 있다. <br />\n",
    "세 번째 Conv 레이어는 3x3x256 크기의 384개 커널을 가지고 두 번째 Conv 레이어의 출력(정규화(normalized)되고 풀링된)에 연결된다. <br /> \n",
    "네 번째 Conv 레이어는 크기가 3x3x192인 384개의 커널을 가지며 다섯 번째 Conv 레이어는 크기가 3x3x192인 256개의 커널을 가진다. <br />\n",
    "Fully-connected 레이어에는 각각 4096개의 뉴런이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reduce Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 뉴럴 네트워크 아키텍처는 60 million 개의 파라미터들을 가지고 있다. <br />\n",
    "비록 ILSVRC의 1000개의 클래스들이 각 학습 예제에 대하여 이미지에서 레이블로의 mapping에 10 비트의 제한을 <br /> \n",
    "가하도록 함에도 불구하고 상당한 과적합없이 많은 매개변수가 학습한다는 것은 불충분하다는 것이 밝혀졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터에 대하여 과적합을 줄이는 가장 쉽고 일반적인 방법은 라벨을 보존한 상태로 변형을 사용해 인공적으로 데이터 셋을 늘리는 것이다. <br />\n",
    "우리는 두 가지 다른 형태의 데이터 augmentation 적용하였다. 두 가지 방법 모두 원본으로부터 변형된 이미지를 생산하는데 매우 작은 계산만을 필요로 하였고, <br />\n",
    "따라서 변형된 이미지는 disk에 저장될 필요가 없다. 우리의 실행에서, 변형된 이미지들은 CPU에서 파이썬 코드로 생성되었고 그동안 GPU는 이미지들의 이전 배치를 학습한다. <\n",
    "그러므로 이런 데이터 augmentation 기법은 효과적이고, 계산적으로 자유롭다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 augmentation의 첫 번째 형태는 이미지 translations와 수평적 reflections로 구성된다. <br />\n",
    "우리는 이를 256x256 이미지들에서 무작위로 224x224 patches를 추출하고 <br /> \n",
    "우리의 네트워크를 이렇게 추출된 patches로 학습하는 것으로 이루어진다. (4) <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (4) 이는 Figure 2의 입력 이미지가 224×224×3 차원인 이유이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 학습 예제들은 물론 서로 상호의존적이지만, 학습 셋의 크기는 2048배 증가한다. <br />\n",
    "이 기법이 없이, 우리 네트워크는 상당한 과적합으로 고통을 겪는다. 이는 우리에게 훨씬 더 작은 네트워크를 사용하도록 만든다. <br />\n",
    "테스트를 진행하는 시점에서, 네트워크는 224×224 patches(4개의 코너 patches와 중앙 patch)와 <br /> \n",
    "수평 reflections(따라서 모두 10개의 patches)를 추출함으로서 예측을 만들고, <br /> \n",
    "10개의 patches에서의 네트워크의 softmax 레이어에 의해 만들어진 예측들의 평균을 낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 augmentation의 두 번째 형태는 학습 이미지에서 RGB 채널의 강도를 변경하는 것으로 구성된다. <br />\n",
    "특히, ImageNet 학습 셋에서 RGB 픽셀 값들의 집합에 대해 PCA를 수행한다. <br />\n",
    "각각의 학습 이미지에 대하여, 우리는 상응하는 eigenvalues에 비례하는 크기를 평균 0 및 표준 편차 0.1을 갖는 <br /> \n",
    "가우시안으로부터 추출된 무작위 변수에 곱함과 함께 발견된 주성분의 배수를 더한다. <br />\n",
    "그러므로 각각의 RGB 이미지 픽셀 ${ I }_{ xy }={ [{ I }_{ xy }^{ R },{ I }_{ xy }^{ G }{ I }_{ xy }^{ B }] }^{ T }$에 우리는 다음 quantitiy를 더한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/4.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 ${p}_{i}$와 ${\\lambda}_{i}$는 각각 RGB 픽셀 값들의 3x3 covariance 행렬의 $i$번째 eigenvector와 eigenvalue이다. 그리고 ${\\alpha}_{i}$는 앞서 말한 확률 변수이다. <br />\n",
    "각각의 ${\\alpha}_{i}$는 그 이미지가 다시 학습을 위해 사용될 때까지(그 점이 re-drawn되는 되는 시점) <br /> \n",
    "특정 학습 이미지의 모든 픽셀에 대하여 한 번만 be drawn 된다. <br />\n",
    "이 기법은 대략적으로 nature 이미지의 중요한 속성을 capture 한다. 즉, 객체의 정체성은 조명의 강도와 색상의 변화에 불변한다. <br />\n",
    "이 기법은 top-1 error rate를 1% 이상 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CF) PCA (주성분 분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주성분 분석(PCA)는 고차원의 데이터를 저차원의 데이터로 환원시키는 기법이다. <br /> \n",
    "서로 연관 가능성이 있는 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간(주성분)의 표본으로 변환하기 위해 직교 변환을 사용한다. <br /> \n",
    "주성분의 차원수는 원래 표본의 차원수보다 작거나 같다. <br /> \n",
    "주성분 분석은 데이터를 한 개의 축으로 사상시켰을 때 그 분산이 가장 커지는 축을 첫 번째 주성분, <br />\n",
    "두 번째로 커지는 축을 두 번째 주성분으로 놓이도록 새로운 좌표계로 데이터를 선형 변환한다. <br /> \n",
    "이와 같이 표본의 차이를 가장 잘 나타내는 성분들로 분해함으로서 여러가지 응용이 가능하다. <br /> \n",
    "이 변환은 첫째 주성분이 가장 큰 분산을 가지고, 이후의 주성분들은 이전의 주성분들과 직교한다는 제약 아래에 <br /> \n",
    "가장 큰 분산을 갖고 있다는 식으로 정의되어있다. 중요한 성분들은 공분산 행렬의 고유 벡터이기 때문에 직교하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 다른 모델의 예측들을 조합하는 것은 테스트 error를 줄이기 위한 매우 성공적인 방법이지만, <br /> \n",
    "이미 학습을 하는데 며칠이나 걸리는 큰 뉴럴 네트워크에는 너무 expensive 한 것으로 보인다. <br /> \n",
    "그러나 학습 중 2배 정도의 cost가 들면서 매우 효율적인 버전의 모델 조합이 있다. <br /> \n",
    "Dropout이라고 불리는 최근 도입된 이 기법은 확률 0.5로 각각의 hidden 뉴런의 출력을 0으로 설정하는 것으로 구성된다. <br /> \n",
    "이런 방식으로 dropped out 된 뉴런은 forward pass에 기여하지 않으며 backpropagation에 참여하지 않는다. <br /> \n",
    "따라서 입력이 제공될 때마다 뉴럴 네트워크는 다른 아키텍처를 samples 하지만, 그러나 이러한 모든 아키텍처는 가중치를 공유한다. <br /> \n",
    "이 기술은 뉴런이 특정 다른 뉴런의 존재에 의존할 수 없으므로 복잡한 뉴런의 co-adaptation을 감소시킨다. <br /> \n",
    "따라서 다른 뉴런들의 많은 다른 무작위 subsets과 함께 유용한 더 robust feature들을 배우게된다. <br /> \n",
    "테스트 할 때, 우리는 모든 뉴런들을 사용하지만 그들의 출력에 0.5를 곱한다. <br /> \n",
    "이는 기하급수적으로 많은 dropout 네트워크에 의해 생성된 예측 분포들의 기하 평균을 취하는 것에 대한 합리적인 근사이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 Figure 2의 처음 두 개의 fully-connected 레이어에서 dropout을 사용한다. <br /> \n",
    "Drop out이 없으면 우리의 네트워크는 상당한 과적합을 나타낸다. <br /> \n",
    "Drop out은 수렴하는데 필요한 반복 횟수를 대략 두 배로 늘린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Details of learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 우리의 모델을 batch-사이즈 128, momentum 0.9, weight decay 0.0005로 설정한 확률적 경사 하강법을 사용하여 학습하였다. <br />\n",
    "우리는 이 작은 양의 weight decay가 모델을 학습하는데 중요하다는 것을 발견했다. <br /> \n",
    "다시 말해, 여기서 weight decay는 순전히 정규화(regularizer)뿐만 아니라 모델의 학습 error를 줄여준다. <br />\n",
    "Weight $w$에 대한 update rule은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/5.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $i$는 반복 횟수 index이고, $v$는 momentum 변수, $\\epsilon $은 learning rate <br />\n",
    "그리고 ${ <\\frac { \\partial L }{ \\partial w } { | }_{ { w }_{ i } }> }_{ { D }_{ i } }$는 $w$에 관한 objective의 미분의 $i$번째 배치 ${D}_{i}$에 대한 평균이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 각 레이어의 가중치들을 표준 편차 0.01 인 0-평균 가우스 분포로부터 초기화했다. <br /> \n",
    "우리는 두 번째, 네 번째 및 다섯 번째 Conv 레이어와 fully-connected hidden 레이어의 뉴런 bias들을 상수 1로 초기화했다. <br />\n",
    "이 초기화는 ReLU에 양수 입력들을 제공하여 학습의 초기단계를 가속화한다. 나머지 레이어들의 뉴런 bias는 상수 0으로 초기화했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 모든 레이어에 대해 동일한 learning rate를 사용했으며, 이를 학습하는 동안 내내 수동으로 조정했다. <br />\n",
    "우리가 쫓아가는 heuristic은 검증 error rate가 현재의 learning rate로 개선되는 것을 멈추었을때, learning rate를 10으로 나누는 것이다. <br /> \n",
    "learning rate는 0.01로 초기화 되었고 종료되기 전까지 3번 감소하였다. <br />\n",
    "우리는 120 million의 이미지 학습 셋을 통해 대략 90 사이클 동안 네트워크를 학습했고 <br /> \n",
    "이는 두 개의 NVIDIA GTX 580 3GB GPU를 사용하여 5일에서 6일정도 걸렸다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ILSVRC-2010에 대한 우리의 결과는 Table 1에 요약되어있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/7.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2010 테스트 셋에 대한 비교의 결과. <br />\n",
    "In italics are best results achieved by others.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 네트워크는 top-1과 top-5에 대하여 학습 셋 error rates를 각각 37.5%와 17.0%를 달성하였다. (5)<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (5) Section 4.1에서 설명하였던 10개의 patches에 대한 예측을 평균하지 않고서의 error rates는 각각 39.0%와 18.3%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2010 대회에서는 서로 다른 features에 대해 학습된 six sparse-coding model에서 생성된 예측들을 평균을 내는 <br /> \n",
    "접근법을 사용하여 각각 47.1%와 28.2%의 성능을 달성하였고 이는 이 대회에서 최고의 성능이었다. <br />\n",
    "이후 가장 우수한 결과는 두 types의 densely-sampled features로부터 계산된 Fisher Vector(FVs)에 대해 <br /> \n",
    "학습된 두 classifiers의 예측을 평균을 낸 접근법을 사용하여 각각 45.7%와 25.7%의 성능을 낸 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 또한 우리의 모델을 가지고 ILSVR-2012에 참가하였고 결과는 Table 2에 요약되어있다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/8.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2012 검증과 테스트 셋에 대한 error rates 비교. <br />\n",
    "In italics are best results achived by others. <br />\n",
    "Asterisk(*)가 있는 모델은 가을에 출시된 전체 ImageNet 2011을 분류함으로 전처리되었다. <br />\n",
    "더 자세한 사항은 Section 6를 보아라.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC-2012 테스트 셋 라벨들이 공개적으로 제공되지 않으면서,\n",
    "우리는 우리가 노력했던 모든 모델들에 대한 테스트 error rates를 보고 할 수 없었다. <br />\n",
    "이 paragraph의 나머지 부분에서, 우리는 검증과 테스트 error rates를 interchangeably하게 사용하였다. <br />\n",
    "왜냐하면 우리의 경험에서는, 그들은 0.1% 이상 차이가 나지 않기 때문이다. (See Table 2) <br />\n",
    "이 논문에서 서술된 CNN은 top-5 error rate를 18.2% 달성하였다. <br />\n",
    "5개의 비슷한 CNNs의 예측의 평균은 16.4%의 error rate를 보여준다. <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 pooling 레이어에 대하여 여분의 6개의 Conv 레이어를 가지고 있고, 2011 가을에 출시된 전체 ImageNet(15M images, 22K categories)을 분류함으로서 전처리한 다음, <br />\n",
    "ILSVRC-2012에 대하여 fine-tuning된 한 학습된 CNN은 16.6%의 error rate를 보여준다. <br />\n",
    "앞에서 언급되었던 5개의 CNNs를 가지고 2011 가을에 출시된 전체 ImageNet에 대하여 전처리된 두 CNNs의 예측의 평균은 error rate 15.3%를 보여준다. <br />\n",
    "두 번째로 우수한 대회 entry는 두 types의 densely-sampled features로부터 계산된 Fisher Vector(FVs)에 대해 \n",
    "학습된 <br /> \n",
    "두 classifiers의 예측을 평균을 낸 접근법으로 26.2 %의 오류율을 달성하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "마지막으로, 우리는 10,184개의 카테고리와 8.9 million 이미지들을 가지고 있는 ImageNet의 <br /> \n",
    "가을 2009 버전에 대한 우리의 error rates 또한 보고하였다. <br /> \n",
    "이 데이터 셋에 대하여 우리는 문헌 그대로 관례를 따라 이미지의 반은 학습에 반은 테스트에 사용하였다. <br />\n",
    "확정된 테스트 셋이 없기 때문에, 우리의 분할은 author가 이전에 사용한 분할과는 필연적으로 달라야한다. <br /> \n",
    "그러나 이는 결과에 눈에띄는 영향을 미치지 않는다. <br />\n",
    "이 데이터 세트에서 우리의 top-1과 top-5의 error rates는 각각 67.4 %와 40.9%이고, <br /> \n",
    "이는 위에서 설명한 네트워크에 의해 달성되지만 마지막 풀링 레이어 위에 추가로 여섯 번째 컨벌루션 레이어가 있다. <br /> \n",
    "이 데이터 세트에서 published 된 가장 좋은 결과는 78.1%와 60.9%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Qualiatative Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3은 네트워크의 두 개의 data-connected 레이어에서 학습된 convolutional kernels를 보여준다. <br /> \n",
    "네트워크는 다양한 frequency와 orientation-selective kernels 뿐만 아니라 다양한 colored blobs를 학습했다. <br />\n",
    "Section 3.5에서 설명하였던 제한된 연결성의 결과로 두 개의 GPU가 나타내는 specialization에 주목하자. <br /> \n",
    "GPU 1의 kernels는 크게 color-agnostic 이지만 GPU 2의 kernels는 색상에 크게 color-specific 이다. <br /> \n",
    "이러한 종류의 specialization은 모든 실행 중에 발생하며 어떤 특정 임의의 가중치 초기화와도 독립적이다.(GPU들의 번호를 재 지정하는 법)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/10.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4 : <br /> \n",
    "(왼쪽) 8개의 ILSVRC-2010 테스트 이미지와 우리 모델에서 가장 가능성이 있다고 여겨지는 5개의 레이블. <br /> \n",
    "올바른 레이블이 각 이미지 아래에 쓰여지고 올바른 레이블에 할당된 확률이 빨간색 막대로 표시된다. (top 5에 있는 경우). <br /> \n",
    "(오른쪽) 첫 번째 열에 5개의 ILSVRC-2010 테스트 이미지. <br /> \n",
    "나머지 열은 테스트 이미지에 대한 feature vector로부터 Euclidean distance가 가장 작은 마지막 hidden 레이어에서의 <br /> \n",
    "feature vectors가 생성하는 여섯 개의 트레이닝 이미지를 보여줍니다.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4의 왼쪽 panel에서, 우리는 네트워크가 8개의 테스트 이미지에 대한 top-5 예측을 계산함으로서 <br /> \n",
    "학습한 것을 qualitatively하게 평가한다. <br />\n",
    "왼쪽 위의 진드기와 같이 중심에서 벗어난 물체도 네트워크에 인식될 수 있다. Top-5 레이블들은 대부분은 합리적으로 보인다. <br /> \n",
    "예를 들어, 표범에 대하여 유일한 다른 유형의 고양이는 그럴싸한 레이블로 간주된다. <br />\n",
    "어떤 경우에는(창살, 체리) 사진의 의도된 초점에 대한 진정한 모호함이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크의 시각적 지식을 관찰하는 또 다른 방법은 마지막 4096차원의 hidden 레이어에서의 이미지에 의해 <br /> \n",
    "유발되는 feature activations를 고려하는 것이다. <br /> \n",
    "만약 두 이미지가 작은 유클리드 분리에 대하여 feature activation vetors를 생성한다면, <br /> \n",
    "우리는 뉴럴 네트워크의 상위 레벨들이 그것들과 상당히 유사하다고 생각할 수 있다. <br /> \n",
    "Figure 4는 테스트 셋의 5개 이미지와 이 측정을 따르는, 각 이미지들과 가장 유사한 6개 이미지를 보여줍니다. <br /> \n",
    "픽셀 수준에서, 검색된 학습 이미지는 일반적으로 L2에서 첫 번째 열의 query 이미지와 가까이 있지 않다. <br /> \n",
    "예를 들어, 검색된 개와 코끼리는 다양한 자세로 나타난다. 보충 자료에서 더 많은 테스트 이미지들에 대한 결과를 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4096 차원의 실수 벡터 두 개 사이를 유클리드 거리를 사용하여 유사성을 계산하는 것은 비효율적이다. <br /> \n",
    "그러나 이 벡터들을 짧은 이진 코드로 압축하도록 auto-encoder로 학습하면 효율적으로 만들 수 있다. <br /> \n",
    "이 방법은, 이미지 라벨을 사용하지 않기 때문에 semantically similar의 여부에 관계없이 가장자리의 비슷한 패턴을 가진 이미지를 <br /> \n",
    "검색하는 경향이 있는 raw pixel에 auto-encoder를 적용하는 방법보다 훨씬 나은 이미지 검색 방법을 만들어낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 결과는 크고 깊은, ConvNet이 순수하게 지도 학습을 사용하여 매우 어려운 데이터 셋을 학습한 결과보다 더 기록적인 결과를 달성 할 수 있음을 보여주었다. <br /> \n",
    "하나의 Conv 레이어가 제거되면 네트워크 성능이 저하된다. 예를 들어, 중간 레이어들 중 하나를 제거하면 네트워크의 top-1 성능에 대해 약 2%의 손실이 발생한다. <br /> \n",
    "깊이는 실제로 우리의 결과를 달성하는데 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "실험을 단순화하기 위해, 우리에게 도움이 될 것이라고 예상됨에도 불구하고 비지도 사전 학습을 사용하지 않았다.\n",
    "특히 만약 우리가 상응하는 라벨화된 데이터의 양의 증가를 달성하지 않으면서 네트워크의 크기를 크게 증가시킬 수 있는 충분한 계산 능력을 얻는다 해도 그렇다. <br />\n",
    "그러므로 지금까지, 우리의 네트워크를 더 크고 길게 학습하면서 우리의 결과는 향상되었지만 우리는 여전히 인간의 시각 체계의 <br /> \n",
    "infero-temporal pathway와 일치시키기 위한 많은 orders of magnitude 가 있다. <br /> \n",
    "궁극적으로 우리는 정적인 이미지에서 누락되거나 덜 명확한 것에 대해 매우 유용한 정보를 제공하는 비디오 시퀀스에 매우 크고 깊은 ConvNet을 사용하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
